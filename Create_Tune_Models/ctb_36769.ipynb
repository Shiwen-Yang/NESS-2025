{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dfe1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize']=10,20\n",
    "\n",
    "# Add the grandparent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "from Utils import FE_helper as FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc8d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the data\n",
    "train_df = pd.read_csv('../Original_Data/train_2025.csv') \n",
    "test_df = pd.read_csv('../Original_Data/test_2025.csv')\n",
    "\n",
    "train_df = FE.add_features(train_df)\n",
    "test_df = FE.add_features(test_df)\n",
    "\n",
    "test_id = test_df['claim_number']\n",
    "train_id = train_df['claim_number']\n",
    "target = train_df['fraud']\n",
    "\n",
    "ignore_var = ['claim_date.is_weekend', 'claim_date.near_holiday', 'fraud']\n",
    "train_df = FE.drop_ignored_columns(train_df, ignore_var)\n",
    "test_df = FE.drop_ignored_columns(test_df, ignore_var)\n",
    "\n",
    "presence_info_df_3 = pd.read_csv('logs/subset_info_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3466b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_presence_columns(train_df, presence_info_df, verbose = False):\n",
    "    \"\"\"\n",
    "    For each combo in presence_info_df, create a presence feature on train_df.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df (pd.DataFrame): The training dataset.\n",
    "    - presence_info_df (pd.DataFrame): DataFrame containing 'feature' column\n",
    "      with names like 'feature1__feature2__feature3_present'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: train_df with new presence columns added.\n",
    "    \"\"\"\n",
    "    df_out = train_df.copy()\n",
    "    \n",
    "    for combo_str in presence_info_df['feature']:\n",
    "        # Extract base combo name (strip trailing '_present')\n",
    "        if combo_str.endswith('_present'):\n",
    "            combo_base = combo_str[:-8]\n",
    "        else:\n",
    "            combo_base = combo_str\n",
    "        \n",
    "        # Split by '__' to get the individual features\n",
    "        combo_features = combo_base.split('__')\n",
    "        new_col_name = combo_base + '_present'  # keep consistent\n",
    "        if verbose:\n",
    "            print(f\"Processing combo: {combo_features}\")\n",
    "        \n",
    "        # Build tuple of feature values per row\n",
    "        combo_tuples = train_df[combo_features].apply(tuple, axis=1)\n",
    "        \n",
    "        # Count how many times each tuple appears\n",
    "        counts = combo_tuples.map(combo_tuples.value_counts())\n",
    "        \n",
    "        # Presence = appears more than once in the dataset\n",
    "        df_out[new_col_name] = (counts > 1).astype(int)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n",
    "def fit_presence_pca(train_df, present_cols, n_components=None, scale=True):\n",
    "    \"\"\"\n",
    "    Fits PCA on presence feature columns in the training set.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df (pd.DataFrame): Training dataset.\n",
    "    - present_cols (list): List of column names for presence features.\n",
    "    - n_components (int or None): Number of PCA components. If None, keep all.\n",
    "    - scale (bool): Whether to standardize columns before PCA.\n",
    "    \n",
    "    Returns:\n",
    "    - pca (PCA object): Fitted PCA object.\n",
    "    - X_train_pca (np.ndarray): Transformed training set (PCA scores).\n",
    "    - scaler (StandardScaler object or None): Fitted scaler if used, else None.\n",
    "    \"\"\"\n",
    "    X = train_df[present_cols].values\n",
    "\n",
    "    # Optionally scale features\n",
    "    scaler = None\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    # Fit PCA\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_train_pca = pca.fit_transform(X)\n",
    "\n",
    "    print(f\"PCA fitted. Explained variance (first 10 components): {pca.explained_variance_ratio_[:10]}\")\n",
    "    return pca, X_train_pca, scaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "def fit_regular_transformer(train_df, presence_suffix='_present'):\n",
    "    # Identify regular columns\n",
    "    regular_cols = [col for col in train_df.columns if not col.endswith(presence_suffix)]\n",
    "    \n",
    "    # Split regular into categorical and numerical\n",
    "    categorical_cols = train_df[regular_cols].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_cols = train_df[regular_cols].select_dtypes(include=['number']).columns.tolist()\n",
    "    if 'claim_number' in numerical_cols:\n",
    "        numerical_cols.remove('claim_number')\n",
    "    \n",
    "    # Initialize transformers\n",
    "    onehot = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit transformers\n",
    "    onehot.fit(train_df[categorical_cols])\n",
    "    scaler.fit(train_df[numerical_cols])\n",
    "    \n",
    "    # print(f\"Fitted on {len(categorical_cols)} categorical and {len(numerical_cols)} numerical columns.\")\n",
    "    \n",
    "    return onehot, scaler, categorical_cols, numerical_cols\n",
    "\n",
    "def transform_regular_set(df, onehot, scaler, categorical_cols, numerical_cols):\n",
    "    # Transform categorical\n",
    "    cat_transformed = onehot.transform(df[categorical_cols])\n",
    "    cat_df = pd.DataFrame(cat_transformed, columns=onehot.get_feature_names_out(categorical_cols), index=df.index)\n",
    "    \n",
    "    # Transform numerical\n",
    "    num_transformed = scaler.transform(df[numerical_cols])\n",
    "    num_df = pd.DataFrame(num_transformed, columns=numerical_cols, index=df.index)\n",
    "    \n",
    "    # Combine transformed parts\n",
    "    transformed_df = pd.concat([num_df, cat_df], axis=1)\n",
    "    \n",
    "    # print(f\"Transformed set shape: {transformed_df.shape}\")\n",
    "    return transformed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69fb3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_df, presence_info_df, target, kfoldcv=5, drop=[]):\n",
    "    # Dynamic feature selection thresholds\n",
    "    # difference_min = trial.suggest_float('difference_min', 0.03, 0.07)\n",
    "    # info_min = trial.suggest_float('info_min', 0.03, 0.05)\n",
    "    difference_min = 0.05\n",
    "    info_min = 0.03\n",
    "    presence_info_df = presence_info_df[\n",
    "        (np.abs(presence_info_df['difference']) > difference_min) &\n",
    "        (presence_info_df['info'] > info_min)\n",
    "    ]\n",
    "\n",
    "    # trial.set_user_attr('difference_min', difference_min)\n",
    "    # trial.set_user_attr('info_min', info_min)\n",
    "\n",
    "    # Add presence features\n",
    "    updated_train_df = add_presence_columns(train_df, presence_info_df)\n",
    "    present_cols = [col for col in updated_train_df.columns if col.endswith('_present')]\n",
    "\n",
    "    # Drop problematic high-cardinality categorical columns\n",
    "    high_dim_cat_cols_to_drop = ['claim_date.day', 'claim_date.dayofweek', 'claim_date.weekofyear',\n",
    "    'claim_date.month', 'zero_payout', 'zero_payout']\n",
    "    updated_train_df.drop(columns=high_dim_cat_cols_to_drop, inplace=True)\n",
    "\n",
    "    # Transform regular features\n",
    "    onehot, scaler, cat_cols, num_cols = fit_regular_transformer(updated_train_df)\n",
    "    X_train_regular = transform_regular_set(updated_train_df, onehot, scaler, cat_cols, num_cols)\n",
    "\n",
    "    # Combine with presence features\n",
    "    full_train_df = pd.concat([X_train_regular, updated_train_df[present_cols]], axis=1)\n",
    "\n",
    "    # Define hyperparameter space\n",
    "    params = {\n",
    "        'iterations': 2000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 25.0, log=True),\n",
    "        'random_seed': 69,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'Logloss',\n",
    "        'verbose': False,\n",
    "        'task_type': 'GPU'  # change to 'GPU' if using GPU\n",
    "    }\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=kfoldcv, shuffle=True, random_state=42)\n",
    "    best_thresholds = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(full_train_df, target):\n",
    "        X_train = full_train_df.iloc[train_idx].drop(columns=drop, errors='ignore')\n",
    "        X_val = full_train_df.iloc[val_idx].drop(columns=drop, errors='ignore')\n",
    "        y_train = target.iloc[train_idx]\n",
    "        y_val = target.iloc[val_idx]\n",
    "        \n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        val_pool = Pool(X_val, y_val)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50)\n",
    "\n",
    "        # Predict + threshold tuning\n",
    "        probs = model.predict_proba(X_val)[:, 1]\n",
    "        thresholds = np.linspace(0.1, 0.9, 50)\n",
    "        f1s = [f1_score(y_val, probs > t) for t in thresholds]\n",
    "\n",
    "        best_f1 = max(f1s)\n",
    "        best_threshold = thresholds[np.argmax(f1s)]\n",
    "\n",
    "        f1_scores.append(best_f1)\n",
    "        best_thresholds.append(best_threshold)\n",
    "\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_threshold = np.mean(best_thresholds)\n",
    "\n",
    "    trial.set_user_attr('mean_threshold', mean_threshold)\n",
    "    trial.set_user_attr('f1_per_fold', f1_scores)\n",
    "\n",
    "    return mean_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900064c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 22:03:27,517] A new study created in memory with name: no-name-424011bc-f1e2-42ca-b820-7adcf0aff4d0\n",
      "[I 2025-05-06 22:07:53,272] Trial 0 finished with value: 0.3702738877237509 and parameters: {'learning_rate': 0.012151459447326506, 'depth': 9, 'l2_leaf_reg': 0.005596719677161326}. Best is trial 0 with value: 0.3702738877237509.\n",
      "[I 2025-05-06 22:09:33,626] Trial 1 finished with value: 0.3748606214118541 and parameters: {'learning_rate': 0.05144740862482892, 'depth': 3, 'l2_leaf_reg': 12.799904108569352}. Best is trial 1 with value: 0.3748606214118541.\n",
      "[I 2025-05-06 22:10:43,575] Trial 2 finished with value: 0.3728339452289898 and parameters: {'learning_rate': 0.08554421169762018, 'depth': 9, 'l2_leaf_reg': 0.6047961580819913}. Best is trial 1 with value: 0.3748606214118541.\n",
      "[I 2025-05-06 22:11:26,390] Trial 3 finished with value: 0.38032983598759956 and parameters: {'learning_rate': 0.08982639660888696, 'depth': 3, 'l2_leaf_reg': 0.20168909054330955}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:14:46,600] Trial 4 finished with value: 0.37671908872807436 and parameters: {'learning_rate': 0.008965757489167536, 'depth': 5, 'l2_leaf_reg': 9.415966415065801}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:16:39,039] Trial 5 finished with value: 0.37502737960022303 and parameters: {'learning_rate': 0.0981550242954686, 'depth': 10, 'l2_leaf_reg': 2.6456881852881464}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:17:16,016] Trial 6 finished with value: 0.3773016222001439 and parameters: {'learning_rate': 0.07016845848924011, 'depth': 5, 'l2_leaf_reg': 3.6709919547490752}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:19:07,451] Trial 7 finished with value: 0.3761589624355446 and parameters: {'learning_rate': 0.015628958822157674, 'depth': 4, 'l2_leaf_reg': 0.006785070094365247}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:20:05,640] Trial 8 finished with value: 0.37644780917890686 and parameters: {'learning_rate': 0.053252657051136895, 'depth': 3, 'l2_leaf_reg': 0.34489094793585656}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:21:03,093] Trial 9 finished with value: 0.36651835098673796 and parameters: {'learning_rate': 0.09163185235536965, 'depth': 10, 'l2_leaf_reg': 0.030946190720245754}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:22:00,086] Trial 10 finished with value: 0.3724917372138292 and parameters: {'learning_rate': 0.037594046515323304, 'depth': 7, 'l2_leaf_reg': 0.05923360794080839}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:22:34,853] Trial 11 finished with value: 0.3768855826172451 and parameters: {'learning_rate': 0.0728844703025858, 'depth': 6, 'l2_leaf_reg': 1.4454284754211089}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:23:05,620] Trial 12 finished with value: 0.3737745664163007 and parameters: {'learning_rate': 0.0743267399410377, 'depth': 5, 'l2_leaf_reg': 0.11053834237682217}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:23:38,181] Trial 13 finished with value: 0.37386595082068425 and parameters: {'learning_rate': 0.0693883182375166, 'depth': 4, 'l2_leaf_reg': 0.001244998736039392}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:24:09,846] Trial 14 finished with value: 0.37341894191236313 and parameters: {'learning_rate': 0.08146364194316742, 'depth': 6, 'l2_leaf_reg': 4.392391692244764}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:25:04,541] Trial 15 finished with value: 0.3768770279368757 and parameters: {'learning_rate': 0.05928990735339796, 'depth': 4, 'l2_leaf_reg': 0.6918359935124193}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:26:17,683] Trial 16 finished with value: 0.3755893276293037 and parameters: {'learning_rate': 0.03350354131373788, 'depth': 7, 'l2_leaf_reg': 19.418401211831114}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:26:58,637] Trial 17 finished with value: 0.3794956426198949 and parameters: {'learning_rate': 0.0963369943682707, 'depth': 3, 'l2_leaf_reg': 0.1384775345818986}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:27:36,346] Trial 18 finished with value: 0.37998593114408424 and parameters: {'learning_rate': 0.0976200264913502, 'depth': 3, 'l2_leaf_reg': 0.027853114121974283}. Best is trial 3 with value: 0.38032983598759956.\n",
      "[I 2025-05-06 22:28:19,996] Trial 19 finished with value: 0.3807932072692478 and parameters: {'learning_rate': 0.08721611739506445, 'depth': 3, 'l2_leaf_reg': 0.014450234977852661}. Best is trial 19 with value: 0.3807932072692478.\n",
      "[I 2025-05-06 22:28:55,954] Trial 20 finished with value: 0.37316529539738413 and parameters: {'learning_rate': 0.08460191013642321, 'depth': 8, 'l2_leaf_reg': 0.009875635782324331}. Best is trial 19 with value: 0.3807932072692478.\n",
      "[I 2025-05-06 22:29:32,948] Trial 21 finished with value: 0.3815807332070035 and parameters: {'learning_rate': 0.09927934860245236, 'depth': 3, 'l2_leaf_reg': 0.024661873391294838}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:30:08,309] Trial 22 finished with value: 0.37429121185806774 and parameters: {'learning_rate': 0.0891191523323378, 'depth': 4, 'l2_leaf_reg': 0.017430918333066446}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:30:50,822] Trial 23 finished with value: 0.37663246386615645 and parameters: {'learning_rate': 0.0807010124833515, 'depth': 3, 'l2_leaf_reg': 0.0018006306189708966}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:31:40,280] Trial 24 finished with value: 0.3742235657394035 and parameters: {'learning_rate': 0.06266815541648417, 'depth': 4, 'l2_leaf_reg': 0.05917254406723143}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:32:26,335] Trial 25 finished with value: 0.37529295024716697 and parameters: {'learning_rate': 0.09042880572099683, 'depth': 5, 'l2_leaf_reg': 0.0028011697629236844}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:33:31,944] Trial 26 finished with value: 0.38051236206091854 and parameters: {'learning_rate': 0.09994545595363324, 'depth': 3, 'l2_leaf_reg': 0.2519991208815828}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:34:02,813] Trial 27 finished with value: 0.37644058588208845 and parameters: {'learning_rate': 0.09859588719242082, 'depth': 4, 'l2_leaf_reg': 0.05743681449262017}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:34:40,821] Trial 28 finished with value: 0.37775508656585866 and parameters: {'learning_rate': 0.07838934868163713, 'depth': 3, 'l2_leaf_reg': 0.014355607281790299}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:35:03,882] Trial 29 finished with value: 0.3723991670368698 and parameters: {'learning_rate': 0.09306756078249205, 'depth': 6, 'l2_leaf_reg': 0.005053115877598881}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:35:31,188] Trial 30 finished with value: 0.3747979745007089 and parameters: {'learning_rate': 0.09975130535651439, 'depth': 5, 'l2_leaf_reg': 0.003716240830773409}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:36:08,229] Trial 31 finished with value: 0.37835648178259507 and parameters: {'learning_rate': 0.08814789314790653, 'depth': 3, 'l2_leaf_reg': 0.3099832058666309}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:36:46,115] Trial 32 finished with value: 0.37902220114165674 and parameters: {'learning_rate': 0.09152491989734365, 'depth': 3, 'l2_leaf_reg': 0.24945955235662792}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:37:18,560] Trial 33 finished with value: 0.3747621556497296 and parameters: {'learning_rate': 0.08497301713118666, 'depth': 4, 'l2_leaf_reg': 0.1252543772447783}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:37:56,569] Trial 34 finished with value: 0.3774424782260682 and parameters: {'learning_rate': 0.07865626642652362, 'depth': 3, 'l2_leaf_reg': 0.03587930213169974}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:38:51,103] Trial 35 finished with value: 0.37388314677737944 and parameters: {'learning_rate': 0.0442425587035129, 'depth': 4, 'l2_leaf_reg': 1.0222865614309855}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:39:35,818] Trial 36 finished with value: 0.3776789880833763 and parameters: {'learning_rate': 0.06422838861249773, 'depth': 3, 'l2_leaf_reg': 0.2087311583448815}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:41:00,228] Trial 37 finished with value: 0.37519172859985855 and parameters: {'learning_rate': 0.02064952552932669, 'depth': 5, 'l2_leaf_reg': 0.5793018918845829}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:41:48,185] Trial 38 finished with value: 0.37311125768920517 and parameters: {'learning_rate': 0.09427513920784382, 'depth': 9, 'l2_leaf_reg': 0.09080248054071301}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:42:23,594] Trial 39 finished with value: 0.37777466305210716 and parameters: {'learning_rate': 0.08588052024717582, 'depth': 3, 'l2_leaf_reg': 0.015318028648621022}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:43:15,086] Trial 40 finished with value: 0.37401635786386594 and parameters: {'learning_rate': 0.07543481982971756, 'depth': 4, 'l2_leaf_reg': 0.47818520958179117}. Best is trial 21 with value: 0.3815807332070035.\n",
      "[I 2025-05-06 22:44:28,554] Trial 41 finished with value: 0.3816004692220901 and parameters: {'learning_rate': 0.09930570612937266, 'depth': 3, 'l2_leaf_reg': 0.020862748392985343}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:45:42,056] Trial 42 finished with value: 0.3798453752662276 and parameters: {'learning_rate': 0.09937004613489754, 'depth': 3, 'l2_leaf_reg': 0.007234299239788977}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:46:45,855] Trial 43 finished with value: 0.37765508020479305 and parameters: {'learning_rate': 0.09400073807676973, 'depth': 3, 'l2_leaf_reg': 0.023142891690685626}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:47:33,584] Trial 44 finished with value: 0.3742861177003262 and parameters: {'learning_rate': 0.08861399399200563, 'depth': 4, 'l2_leaf_reg': 0.039966195921417584}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:48:42,079] Trial 45 finished with value: 0.3767010410588778 and parameters: {'learning_rate': 0.09452748828322702, 'depth': 3, 'l2_leaf_reg': 0.08411972347904588}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:49:37,545] Trial 46 finished with value: 0.3745959103489828 and parameters: {'learning_rate': 0.08328162677981703, 'depth': 4, 'l2_leaf_reg': 0.17390838967360356}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:50:16,955] Trial 47 finished with value: 0.37363491113231395 and parameters: {'learning_rate': 0.0945427708396473, 'depth': 5, 'l2_leaf_reg': 0.008282363092218794}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:51:40,727] Trial 48 finished with value: 0.37646705990431306 and parameters: {'learning_rate': 0.07083906474607078, 'depth': 3, 'l2_leaf_reg': 1.7417692465785097}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:53:15,909] Trial 49 finished with value: 0.37005012577299157 and parameters: {'learning_rate': 0.08864394318229067, 'depth': 10, 'l2_leaf_reg': 0.4067664398374317}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:54:05,476] Trial 50 finished with value: 0.3722527863282982 and parameters: {'learning_rate': 0.09958636538154865, 'depth': 8, 'l2_leaf_reg': 0.04402115936544208}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:55:08,090] Trial 51 finished with value: 0.3776909287030469 and parameters: {'learning_rate': 0.0961110609591355, 'depth': 3, 'l2_leaf_reg': 0.022612629850352374}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:56:10,456] Trial 52 finished with value: 0.37896678902744213 and parameters: {'learning_rate': 0.09973077849563791, 'depth': 3, 'l2_leaf_reg': 0.011975950867505093}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:57:06,887] Trial 53 finished with value: 0.3765608188848728 and parameters: {'learning_rate': 0.09244437557036891, 'depth': 4, 'l2_leaf_reg': 0.024823103230980803}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:57:58,342] Trial 54 finished with value: 0.37687688546056697 and parameters: {'learning_rate': 0.08648994361837802, 'depth': 3, 'l2_leaf_reg': 0.0042787905625302665}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:58:33,717] Trial 55 finished with value: 0.38030730262290785 and parameters: {'learning_rate': 0.09592281215230003, 'depth': 3, 'l2_leaf_reg': 0.07152496074048552}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 22:59:09,158] Trial 56 finished with value: 0.3793027869190209 and parameters: {'learning_rate': 0.09065509401448364, 'depth': 4, 'l2_leaf_reg': 0.08057886054621241}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:00:03,136] Trial 57 finished with value: 0.37879403271890844 and parameters: {'learning_rate': 0.05365660583861485, 'depth': 3, 'l2_leaf_reg': 0.837708505303096}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:00:35,232] Trial 58 finished with value: 0.3753803072779041 and parameters: {'learning_rate': 0.08185106152906854, 'depth': 4, 'l2_leaf_reg': 0.05384795865381377}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:01:10,204] Trial 59 finished with value: 0.37854268967964544 and parameters: {'learning_rate': 0.0964244468022507, 'depth': 3, 'l2_leaf_reg': 0.15375713267746174}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:01:49,477] Trial 60 finished with value: 0.3787419818082734 and parameters: {'learning_rate': 0.07809191114568448, 'depth': 3, 'l2_leaf_reg': 0.018572377945764298}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:02:26,387] Trial 61 finished with value: 0.37716421928472743 and parameters: {'learning_rate': 0.09137082485446785, 'depth': 3, 'l2_leaf_reg': 0.03327129174063899}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:02:54,219] Trial 62 finished with value: 0.3732062447796357 and parameters: {'learning_rate': 0.09661198047943782, 'depth': 4, 'l2_leaf_reg': 0.01104741959299149}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:03:31,227] Trial 63 finished with value: 0.3792920165966021 and parameters: {'learning_rate': 0.09627507960354068, 'depth': 3, 'l2_leaf_reg': 0.2698436184550968}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:04:07,214] Trial 64 finished with value: 0.37780796069840095 and parameters: {'learning_rate': 0.08735283657342652, 'depth': 3, 'l2_leaf_reg': 0.0757045805730468}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:04:36,388] Trial 65 finished with value: 0.37521538569369495 and parameters: {'learning_rate': 0.09121274322994473, 'depth': 4, 'l2_leaf_reg': 0.027901272982521538}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:05:14,854] Trial 66 finished with value: 0.3782309639346777 and parameters: {'learning_rate': 0.08421436469819339, 'depth': 3, 'l2_leaf_reg': 0.10612837932624987}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:06:16,266] Trial 67 finished with value: 0.37663161354743424 and parameters: {'learning_rate': 0.02925350952948262, 'depth': 4, 'l2_leaf_reg': 0.04775489901652385}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:06:52,888] Trial 68 finished with value: 0.3790235377591225 and parameters: {'learning_rate': 0.09629563930546027, 'depth': 3, 'l2_leaf_reg': 0.006070046680655542}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:07:21,544] Trial 69 finished with value: 0.37118695199932467 and parameters: {'learning_rate': 0.09292968494740644, 'depth': 7, 'l2_leaf_reg': 0.002685818988735595}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:12:03,763] Trial 70 finished with value: 0.37505949765085767 and parameters: {'learning_rate': 0.005425172057476238, 'depth': 5, 'l2_leaf_reg': 5.376275191595148}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:12:41,809] Trial 71 finished with value: 0.37824014226406605 and parameters: {'learning_rate': 0.0993321326543971, 'depth': 3, 'l2_leaf_reg': 0.007929331245364577}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:13:16,753] Trial 72 finished with value: 0.3787237164436644 and parameters: {'learning_rate': 0.09995727358523164, 'depth': 3, 'l2_leaf_reg': 0.018379337581845522}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:14:01,007] Trial 73 finished with value: 0.3774915799643507 and parameters: {'learning_rate': 0.09700766714454541, 'depth': 3, 'l2_leaf_reg': 0.012627411712195936}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:14:33,217] Trial 74 finished with value: 0.37929373304354314 and parameters: {'learning_rate': 0.09334189433967492, 'depth': 3, 'l2_leaf_reg': 0.007605796828052031}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:15:12,079] Trial 75 finished with value: 0.3814782275629512 and parameters: {'learning_rate': 0.08936530646203536, 'depth': 3, 'l2_leaf_reg': 0.033814639178363054}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:15:45,501] Trial 76 finished with value: 0.3732722846574895 and parameters: {'learning_rate': 0.08995106780579468, 'depth': 4, 'l2_leaf_reg': 0.21858353640916953}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:16:19,974] Trial 77 finished with value: 0.37928535602953006 and parameters: {'learning_rate': 0.08224230766492227, 'depth': 4, 'l2_leaf_reg': 0.05958525849473267}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:17:09,315] Trial 78 finished with value: 0.3775780542152725 and parameters: {'learning_rate': 0.06653848515576344, 'depth': 3, 'l2_leaf_reg': 0.030155598917134388}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:17:53,660] Trial 79 finished with value: 0.3779120289726925 and parameters: {'learning_rate': 0.08604363458928636, 'depth': 3, 'l2_leaf_reg': 0.12349393683281368}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:18:45,367] Trial 80 finished with value: 0.3778212685603002 and parameters: {'learning_rate': 0.08881171971877788, 'depth': 3, 'l2_leaf_reg': 0.06439079965611286}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:19:34,102] Trial 81 finished with value: 0.37699663561433505 and parameters: {'learning_rate': 0.09436670199493372, 'depth': 3, 'l2_leaf_reg': 0.01599235884984067}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:20:16,226] Trial 82 finished with value: 0.37736651011339506 and parameters: {'learning_rate': 0.09757414385253156, 'depth': 3, 'l2_leaf_reg': 0.040059712421601695}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:21:05,657] Trial 83 finished with value: 0.378032121083661 and parameters: {'learning_rate': 0.0982585982974774, 'depth': 3, 'l2_leaf_reg': 0.009430030656968716}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:21:55,883] Trial 84 finished with value: 0.38119054943835706 and parameters: {'learning_rate': 0.09447943789399403, 'depth': 3, 'l2_leaf_reg': 0.02130576418000945}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:22:36,194] Trial 85 finished with value: 0.37845682643346257 and parameters: {'learning_rate': 0.09150625689993645, 'depth': 4, 'l2_leaf_reg': 0.019636166438903997}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:23:30,753] Trial 86 finished with value: 0.3780140510010934 and parameters: {'learning_rate': 0.07992123925684266, 'depth': 3, 'l2_leaf_reg': 0.029784760858659286}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:24:08,478] Trial 87 finished with value: 0.3766227652361548 and parameters: {'learning_rate': 0.09500370078672887, 'depth': 4, 'l2_leaf_reg': 0.38839792754604774}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:25:42,779] Trial 88 finished with value: 0.3765112426635675 and parameters: {'learning_rate': 0.04508205554613168, 'depth': 3, 'l2_leaf_reg': 0.02454658876334787}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:26:21,774] Trial 89 finished with value: 0.3715883461554618 and parameters: {'learning_rate': 0.07510479249300467, 'depth': 6, 'l2_leaf_reg': 0.1797430094700776}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:27:01,396] Trial 90 finished with value: 0.37863222269985514 and parameters: {'learning_rate': 0.08745383291402861, 'depth': 3, 'l2_leaf_reg': 0.013074335451357902}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:27:49,143] Trial 91 finished with value: 0.3790624341001555 and parameters: {'learning_rate': 0.0983149711356547, 'depth': 3, 'l2_leaf_reg': 0.004754290815168877}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:28:33,860] Trial 92 finished with value: 0.37909996799544377 and parameters: {'learning_rate': 0.09291933252295438, 'depth': 3, 'l2_leaf_reg': 0.038125641303619076}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:29:22,838] Trial 93 finished with value: 0.3776127647000156 and parameters: {'learning_rate': 0.08974209797917031, 'depth': 3, 'l2_leaf_reg': 0.10058288334064372}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:30:08,155] Trial 94 finished with value: 0.36727981519370567 and parameters: {'learning_rate': 0.09628218548978358, 'depth': 9, 'l2_leaf_reg': 0.015586046310922766}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:30:58,885] Trial 95 finished with value: 0.3799295507417045 and parameters: {'learning_rate': 0.0942281347314794, 'depth': 3, 'l2_leaf_reg': 0.06687864969834377}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:31:50,640] Trial 96 finished with value: 0.3785039174785335 and parameters: {'learning_rate': 0.08471241819292338, 'depth': 3, 'l2_leaf_reg': 0.048553587235478424}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:32:27,759] Trial 97 finished with value: 0.37662101445860174 and parameters: {'learning_rate': 0.09528871881981381, 'depth': 4, 'l2_leaf_reg': 0.14089024588890922}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:33:09,313] Trial 98 finished with value: 0.3719158811295755 and parameters: {'learning_rate': 0.09176232390677404, 'depth': 8, 'l2_leaf_reg': 0.07444789814999452}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:34:00,501] Trial 99 finished with value: 0.37760209898801833 and parameters: {'learning_rate': 0.09788090735746652, 'depth': 3, 'l2_leaf_reg': 0.021610563056380077}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:34:47,391] Trial 100 finished with value: 0.37840473010298353 and parameters: {'learning_rate': 0.0936177191264079, 'depth': 3, 'l2_leaf_reg': 0.320298598801923}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:35:34,410] Trial 101 finished with value: 0.3775433403741456 and parameters: {'learning_rate': 0.09988569160055104, 'depth': 3, 'l2_leaf_reg': 0.010891003730737554}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:36:42,777] Trial 102 finished with value: 0.3762767755623078 and parameters: {'learning_rate': 0.05724124751394406, 'depth': 3, 'l2_leaf_reg': 0.03293059891340255}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:37:30,958] Trial 103 finished with value: 0.38000056078330585 and parameters: {'learning_rate': 0.08958554266819832, 'depth': 3, 'l2_leaf_reg': 0.00673863486388226}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:38:16,762] Trial 104 finished with value: 0.376506484922008 and parameters: {'learning_rate': 0.08891437791265114, 'depth': 3, 'l2_leaf_reg': 0.005876916688345069}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:39:02,906] Trial 105 finished with value: 0.3765693784550378 and parameters: {'learning_rate': 0.08729529912283561, 'depth': 4, 'l2_leaf_reg': 0.06572165314443267}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:39:43,980] Trial 106 finished with value: 0.3784255485067596 and parameters: {'learning_rate': 0.09490322072925747, 'depth': 3, 'l2_leaf_reg': 0.002733191737527953}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:40:31,499] Trial 107 finished with value: 0.3787628771453255 and parameters: {'learning_rate': 0.09045285247195972, 'depth': 3, 'l2_leaf_reg': 0.0034742992888470766}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:41:27,777] Trial 108 finished with value: 0.37877631470541073 and parameters: {'learning_rate': 0.08283741109714447, 'depth': 3, 'l2_leaf_reg': 0.047300651001014264}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:42:08,269] Trial 109 finished with value: 0.375471780728012 and parameters: {'learning_rate': 0.09768291346639474, 'depth': 4, 'l2_leaf_reg': 0.026010620207648803}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:45:10,563] Trial 110 finished with value: 0.3774875364303853 and parameters: {'learning_rate': 0.016835974932948354, 'depth': 3, 'l2_leaf_reg': 0.21037716959800407}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:46:00,816] Trial 111 finished with value: 0.3795590416808913 and parameters: {'learning_rate': 0.09268840082730706, 'depth': 3, 'l2_leaf_reg': 0.0018193971495254282}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:46:43,431] Trial 112 finished with value: 0.37885609683550914 and parameters: {'learning_rate': 0.09769261491342703, 'depth': 3, 'l2_leaf_reg': 0.008744244991836687}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:47:27,497] Trial 113 finished with value: 0.3815672951404204 and parameters: {'learning_rate': 0.09515106051929334, 'depth': 3, 'l2_leaf_reg': 0.01342858060762911}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:48:12,785] Trial 114 finished with value: 0.37925028358412555 and parameters: {'learning_rate': 0.09506818628402118, 'depth': 3, 'l2_leaf_reg': 0.01363143653913724}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:49:03,740] Trial 115 finished with value: 0.3775878435331385 and parameters: {'learning_rate': 0.08621876593232357, 'depth': 3, 'l2_leaf_reg': 0.021528245783137355}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:49:56,268] Trial 116 finished with value: 0.38003447980605826 and parameters: {'learning_rate': 0.0901816586584553, 'depth': 3, 'l2_leaf_reg': 0.01675823565929263}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:50:44,802] Trial 117 finished with value: 0.37854017705530224 and parameters: {'learning_rate': 0.08999890914414495, 'depth': 3, 'l2_leaf_reg': 0.018091060359191273}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:51:25,739] Trial 118 finished with value: 0.37565761088966804 and parameters: {'learning_rate': 0.09145486694465021, 'depth': 4, 'l2_leaf_reg': 0.010929709635557542}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:52:17,126] Trial 119 finished with value: 0.3754472360212818 and parameters: {'learning_rate': 0.08424397421639494, 'depth': 3, 'l2_leaf_reg': 0.03725916945306822}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:53:03,611] Trial 120 finished with value: 0.3800101703965764 and parameters: {'learning_rate': 0.09993869248875899, 'depth': 3, 'l2_leaf_reg': 0.5228027903416669}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:53:46,218] Trial 121 finished with value: 0.3785528219914268 and parameters: {'learning_rate': 0.09740773418546206, 'depth': 3, 'l2_leaf_reg': 0.27186333479716224}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:54:34,265] Trial 122 finished with value: 0.3793466827183127 and parameters: {'learning_rate': 0.09584128879487264, 'depth': 3, 'l2_leaf_reg': 0.7581142995246541}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:55:25,322] Trial 123 finished with value: 0.38102853782541246 and parameters: {'learning_rate': 0.09984764881592921, 'depth': 3, 'l2_leaf_reg': 0.5485916366244019}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:56:07,936] Trial 124 finished with value: 0.37792468464934303 and parameters: {'learning_rate': 0.0991235790050762, 'depth': 3, 'l2_leaf_reg': 0.6086919646476154}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:56:51,701] Trial 125 finished with value: 0.3787151960913525 and parameters: {'learning_rate': 0.09281305658904747, 'depth': 3, 'l2_leaf_reg': 0.4711113958264719}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:57:38,459] Trial 126 finished with value: 0.3785754467523634 and parameters: {'learning_rate': 0.09972244442184564, 'depth': 3, 'l2_leaf_reg': 0.5129784545155162}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:58:27,627] Trial 127 finished with value: 0.377232026939344 and parameters: {'learning_rate': 0.08769453279746878, 'depth': 3, 'l2_leaf_reg': 1.2662726444885914}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-06 23:59:12,786] Trial 128 finished with value: 0.3785585265100377 and parameters: {'learning_rate': 0.09542305799092429, 'depth': 3, 'l2_leaf_reg': 2.351734219917898}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:01:16,190] Trial 129 finished with value: 0.3767922392895642 and parameters: {'learning_rate': 0.027672693168613066, 'depth': 3, 'l2_leaf_reg': 0.39020103865051287}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:01:55,520] Trial 130 finished with value: 0.3739448627148286 and parameters: {'learning_rate': 0.09304023582808646, 'depth': 4, 'l2_leaf_reg': 24.072762125004562}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:02:45,397] Trial 131 finished with value: 0.3792193359650029 and parameters: {'learning_rate': 0.0967564999210679, 'depth': 3, 'l2_leaf_reg': 0.9979201781497592}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:03:34,156] Trial 132 finished with value: 0.37771836332159875 and parameters: {'learning_rate': 0.09825412090605579, 'depth': 3, 'l2_leaf_reg': 0.028942852155906588}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:04:28,820] Trial 133 finished with value: 0.38035205878505485 and parameters: {'learning_rate': 0.09083932339297512, 'depth': 3, 'l2_leaf_reg': 0.015083234768110137}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:05:17,456] Trial 134 finished with value: 0.37963493321870184 and parameters: {'learning_rate': 0.09107146843092156, 'depth': 3, 'l2_leaf_reg': 0.015448571369400884}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:06:09,450] Trial 135 finished with value: 0.3803659272388485 and parameters: {'learning_rate': 0.08934601235185263, 'depth': 3, 'l2_leaf_reg': 0.019680406463429598}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:06:56,153] Trial 136 finished with value: 0.37814834783536166 and parameters: {'learning_rate': 0.09403314131673352, 'depth': 3, 'l2_leaf_reg': 0.01963881596772743}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:07:46,255] Trial 137 finished with value: 0.37790640218728033 and parameters: {'learning_rate': 0.08058566018926938, 'depth': 3, 'l2_leaf_reg': 0.014892454937719644}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:08:39,159] Trial 138 finished with value: 0.3789767504318295 and parameters: {'learning_rate': 0.0860541474530022, 'depth': 3, 'l2_leaf_reg': 0.026083983419744584}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:09:19,691] Trial 139 finished with value: 0.37775574805707335 and parameters: {'learning_rate': 0.08874393868693625, 'depth': 3, 'l2_leaf_reg': 0.009979528860097788}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:09:51,724] Trial 140 finished with value: 0.3754027045432824 and parameters: {'learning_rate': 0.09616256688525932, 'depth': 4, 'l2_leaf_reg': 0.012682521039966196}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:10:41,838] Trial 141 finished with value: 0.38060780032860986 and parameters: {'learning_rate': 0.08959474699319712, 'depth': 3, 'l2_leaf_reg': 0.017495720427807386}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:11:33,515] Trial 142 finished with value: 0.3792259402775238 and parameters: {'learning_rate': 0.09161772047481076, 'depth': 3, 'l2_leaf_reg': 0.01754482641025038}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:12:22,798] Trial 143 finished with value: 0.37622745057772045 and parameters: {'learning_rate': 0.09977906672485537, 'depth': 3, 'l2_leaf_reg': 0.025579883974713075}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:13:17,915] Trial 144 finished with value: 0.380973105754952 and parameters: {'learning_rate': 0.09363172113680482, 'depth': 3, 'l2_leaf_reg': 0.02186791347958924}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:14:09,921] Trial 145 finished with value: 0.3771588542644019 and parameters: {'learning_rate': 0.08841994989469554, 'depth': 3, 'l2_leaf_reg': 0.019594913143604308}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:14:58,634] Trial 146 finished with value: 0.3743959292831586 and parameters: {'learning_rate': 0.09355798512471615, 'depth': 3, 'l2_leaf_reg': 0.01317792576841831}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:15:44,967] Trial 147 finished with value: 0.3784516629416279 and parameters: {'learning_rate': 0.09052850942849665, 'depth': 3, 'l2_leaf_reg': 0.034591449877609044}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:16:38,582] Trial 148 finished with value: 0.379532563750354 and parameters: {'learning_rate': 0.08605241306533201, 'depth': 3, 'l2_leaf_reg': 0.021618797150476505}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:17:27,650] Trial 149 finished with value: 0.37785817236623603 and parameters: {'learning_rate': 0.09520507006921954, 'depth': 3, 'l2_leaf_reg': 0.016330464362583858}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:18:22,643] Trial 150 finished with value: 0.3720187565851255 and parameters: {'learning_rate': 0.04642642459904211, 'depth': 7, 'l2_leaf_reg': 0.00944570230466796}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:19:20,003] Trial 151 finished with value: 0.37897074044454954 and parameters: {'learning_rate': 0.09817140579482396, 'depth': 3, 'l2_leaf_reg': 0.031468311932928754}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:20:10,688] Trial 152 finished with value: 0.37929231183535567 and parameters: {'learning_rate': 0.09251340642480944, 'depth': 3, 'l2_leaf_reg': 0.1773858327402079}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:20:54,207] Trial 153 finished with value: 0.3766960466723918 and parameters: {'learning_rate': 0.09685725803401177, 'depth': 3, 'l2_leaf_reg': 0.022501105309681538}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:21:45,138] Trial 154 finished with value: 0.37938783998511516 and parameters: {'learning_rate': 0.09412210752953762, 'depth': 3, 'l2_leaf_reg': 0.33774940303586526}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:22:39,043] Trial 155 finished with value: 0.3800448514554785 and parameters: {'learning_rate': 0.08989540376022224, 'depth': 3, 'l2_leaf_reg': 0.011175927770114944}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:23:27,663] Trial 156 finished with value: 0.3782447031904743 and parameters: {'learning_rate': 0.08348058631541912, 'depth': 3, 'l2_leaf_reg': 0.011594441815770967}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:24:15,362] Trial 157 finished with value: 0.3809295126305957 and parameters: {'learning_rate': 0.08941847749308914, 'depth': 3, 'l2_leaf_reg': 0.01617674315702169}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:24:58,248] Trial 158 finished with value: 0.37938708477165156 and parameters: {'learning_rate': 0.08785883176245338, 'depth': 3, 'l2_leaf_reg': 0.008220313831042297}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:25:52,611] Trial 159 finished with value: 0.38004503048663535 and parameters: {'learning_rate': 0.09101706237500745, 'depth': 3, 'l2_leaf_reg': 0.04243428716589869}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:26:47,700] Trial 160 finished with value: 0.381101630179202 and parameters: {'learning_rate': 0.09212252784225931, 'depth': 3, 'l2_leaf_reg': 0.043321118094952885}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:27:39,106] Trial 161 finished with value: 0.37665380578214047 and parameters: {'learning_rate': 0.09210226244025789, 'depth': 3, 'l2_leaf_reg': 0.04558046422236106}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:28:23,161] Trial 162 finished with value: 0.3784495280086917 and parameters: {'learning_rate': 0.09512168050854446, 'depth': 3, 'l2_leaf_reg': 0.05385738021872476}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:28:57,781] Trial 163 finished with value: 0.37367927483989216 and parameters: {'learning_rate': 0.08808850966292954, 'depth': 6, 'l2_leaf_reg': 0.03769704937994943}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:29:49,322] Trial 164 finished with value: 0.3754567893256223 and parameters: {'learning_rate': 0.08509051245418012, 'depth': 3, 'l2_leaf_reg': 0.0273921624966989}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:30:59,347] Trial 165 finished with value: 0.36917146626448416 and parameters: {'learning_rate': 0.09176138368913643, 'depth': 10, 'l2_leaf_reg': 0.1142640717819272}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:31:47,268] Trial 166 finished with value: 0.37803144792768134 and parameters: {'learning_rate': 0.09692858306316283, 'depth': 3, 'l2_leaf_reg': 0.040372278610635554}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:32:39,232] Trial 167 finished with value: 0.37764533389702776 and parameters: {'learning_rate': 0.09386321106337397, 'depth': 3, 'l2_leaf_reg': 0.023543876864783805}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:33:28,786] Trial 168 finished with value: 0.3770878931930682 and parameters: {'learning_rate': 0.09050654102033852, 'depth': 3, 'l2_leaf_reg': 0.019335173127097996}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:34:15,775] Trial 169 finished with value: 0.37693375586715383 and parameters: {'learning_rate': 0.0954061477032612, 'depth': 3, 'l2_leaf_reg': 0.030722420435591494}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:34:53,690] Trial 170 finished with value: 0.3746528511286295 and parameters: {'learning_rate': 0.08704601397471232, 'depth': 4, 'l2_leaf_reg': 0.01585012774317623}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:35:46,753] Trial 171 finished with value: 0.3791775936809599 and parameters: {'learning_rate': 0.08936648060369354, 'depth': 3, 'l2_leaf_reg': 0.012992904313572489}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:36:37,584] Trial 172 finished with value: 0.3792185025204374 and parameters: {'learning_rate': 0.08955930864336059, 'depth': 3, 'l2_leaf_reg': 0.08442376955255025}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:37:25,148] Trial 173 finished with value: 0.37958143947757306 and parameters: {'learning_rate': 0.09263991458080799, 'depth': 3, 'l2_leaf_reg': 0.2475374513840798}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:38:57,390] Trial 174 finished with value: 0.3767890076078932 and parameters: {'learning_rate': 0.03884191783479588, 'depth': 3, 'l2_leaf_reg': 0.02238637168560997}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:39:42,528] Trial 175 finished with value: 0.37711612854473886 and parameters: {'learning_rate': 0.09765201446664608, 'depth': 3, 'l2_leaf_reg': 0.01072626042834207}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:40:29,929] Trial 176 finished with value: 0.377640109797666 and parameters: {'learning_rate': 0.0912353955776993, 'depth': 3, 'l2_leaf_reg': 0.014488064163773502}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:41:20,033] Trial 177 finished with value: 0.378692254747306 and parameters: {'learning_rate': 0.09347391831628891, 'depth': 3, 'l2_leaf_reg': 0.019411770115319023}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:42:08,497] Trial 178 finished with value: 0.37887358740474636 and parameters: {'learning_rate': 0.09671646548435622, 'depth': 3, 'l2_leaf_reg': 0.048159095137388835}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:43:03,224] Trial 179 finished with value: 0.37818925730944997 and parameters: {'learning_rate': 0.08668443601078468, 'depth': 3, 'l2_leaf_reg': 0.03027774244925124}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:43:52,355] Trial 180 finished with value: 0.37725825643729527 and parameters: {'learning_rate': 0.0894304186771492, 'depth': 3, 'l2_leaf_reg': 0.02520671984109106}. Best is trial 41 with value: 0.3816004692220901.\n",
      "[I 2025-05-07 00:44:40,353] Trial 181 finished with value: 0.3817964812636329 and parameters: {'learning_rate': 0.08943465486972843, 'depth': 3, 'l2_leaf_reg': 0.01622233983575132}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:45:30,734] Trial 182 finished with value: 0.3789817962958092 and parameters: {'learning_rate': 0.08445566226645286, 'depth': 3, 'l2_leaf_reg': 0.016740869560813724}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:46:22,227] Trial 183 finished with value: 0.37814522097545356 and parameters: {'learning_rate': 0.09206583598055221, 'depth': 3, 'l2_leaf_reg': 0.011853800062489735}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:47:10,340] Trial 184 finished with value: 0.377753968284328 and parameters: {'learning_rate': 0.09455554919091484, 'depth': 3, 'l2_leaf_reg': 0.01425959841693698}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:47:56,196] Trial 185 finished with value: 0.3772417387141448 and parameters: {'learning_rate': 0.09998503888897146, 'depth': 3, 'l2_leaf_reg': 9.829945193898274}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:48:48,221] Trial 186 finished with value: 0.3798683905340133 and parameters: {'learning_rate': 0.08821520497929447, 'depth': 3, 'l2_leaf_reg': 0.018517535870201374}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:49:40,271] Trial 187 finished with value: 0.37695227225771283 and parameters: {'learning_rate': 0.09012176327430846, 'depth': 3, 'l2_leaf_reg': 0.03591982760972097}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:50:28,480] Trial 188 finished with value: 0.3762197143517837 and parameters: {'learning_rate': 0.09823206219720161, 'depth': 3, 'l2_leaf_reg': 0.00897397595789828}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:51:15,430] Trial 189 finished with value: 0.37925474533463105 and parameters: {'learning_rate': 0.095242202655135, 'depth': 3, 'l2_leaf_reg': 0.006972746940903953}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:52:14,483] Trial 190 finished with value: 0.37628098622819256 and parameters: {'learning_rate': 0.07185131399092302, 'depth': 3, 'l2_leaf_reg': 0.021625372425853693}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:53:08,755] Trial 191 finished with value: 0.37962139771450726 and parameters: {'learning_rate': 0.09077568221667204, 'depth': 3, 'l2_leaf_reg': 0.017206690043690607}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:54:08,374] Trial 192 finished with value: 0.3777963889366802 and parameters: {'learning_rate': 0.08692205970109936, 'depth': 3, 'l2_leaf_reg': 0.15164334014029585}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:54:53,371] Trial 193 finished with value: 0.3766109834552488 and parameters: {'learning_rate': 0.09309344179484053, 'depth': 3, 'l2_leaf_reg': 0.015316607325557223}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:55:49,269] Trial 194 finished with value: 0.37960090107740996 and parameters: {'learning_rate': 0.08990310494498358, 'depth': 3, 'l2_leaf_reg': 0.026094498578253945}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:56:45,790] Trial 195 finished with value: 0.3793487467030103 and parameters: {'learning_rate': 0.08851536954671932, 'depth': 3, 'l2_leaf_reg': 0.01189181341195639}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:57:21,785] Trial 196 finished with value: 0.3754729565279237 and parameters: {'learning_rate': 0.09166880779865143, 'depth': 5, 'l2_leaf_reg': 0.017641230311420057}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:58:19,041] Trial 197 finished with value: 0.3796887650650728 and parameters: {'learning_rate': 0.08559177266955577, 'depth': 3, 'l2_leaf_reg': 0.02227944876525895}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:59:00,739] Trial 198 finished with value: 0.37975052391025266 and parameters: {'learning_rate': 0.09422387296930708, 'depth': 3, 'l2_leaf_reg': 0.014172050529743536}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 00:59:59,014] Trial 199 finished with value: 0.378483654501977 and parameters: {'learning_rate': 0.08191378725190741, 'depth': 3, 'l2_leaf_reg': 0.009878297945628408}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:00:43,845] Trial 200 finished with value: 0.3769055399619584 and parameters: {'learning_rate': 0.09707418335575417, 'depth': 3, 'l2_leaf_reg': 0.03106064880454979}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:01:31,191] Trial 201 finished with value: 0.37850096089151963 and parameters: {'learning_rate': 0.09985919267740247, 'depth': 3, 'l2_leaf_reg': 0.6889500292325091}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:02:32,679] Trial 202 finished with value: 0.3798144877650912 and parameters: {'learning_rate': 0.0686794402065399, 'depth': 3, 'l2_leaf_reg': 0.8662548338651215}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:03:21,667] Trial 203 finished with value: 0.37864021548672744 and parameters: {'learning_rate': 0.09814063669531885, 'depth': 3, 'l2_leaf_reg': 0.5862543059375191}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:04:13,854] Trial 204 finished with value: 0.3799064412007129 and parameters: {'learning_rate': 0.09841990434379705, 'depth': 3, 'l2_leaf_reg': 0.4859156769666892}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:05:20,598] Trial 205 finished with value: 0.3776898698619599 and parameters: {'learning_rate': 0.060325696681880245, 'depth': 3, 'l2_leaf_reg': 0.2041132072625132}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:06:19,120] Trial 206 finished with value: 0.37951355102858775 and parameters: {'learning_rate': 0.0960638575563512, 'depth': 3, 'l2_leaf_reg': 0.01829586893820263}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:07:07,458] Trial 207 finished with value: 0.37801028787552077 and parameters: {'learning_rate': 0.09313583295950374, 'depth': 3, 'l2_leaf_reg': 0.05982900701580331}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:07:57,954] Trial 208 finished with value: 0.37753647145616787 and parameters: {'learning_rate': 0.09980945483671151, 'depth': 3, 'l2_leaf_reg': 0.04114302034578946}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:08:46,992] Trial 209 finished with value: 0.37861785179228036 and parameters: {'learning_rate': 0.09084709625228314, 'depth': 3, 'l2_leaf_reg': 0.02359835820992512}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:09:31,589] Trial 210 finished with value: 0.37971323606681057 and parameters: {'learning_rate': 0.0959721706608104, 'depth': 3, 'l2_leaf_reg': 0.2565389187598981}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:10:14,588] Trial 211 finished with value: 0.37787558041303715 and parameters: {'learning_rate': 0.0893744070702515, 'depth': 3, 'l2_leaf_reg': 0.006719084451244344}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:11:01,816] Trial 212 finished with value: 0.3777745118065633 and parameters: {'learning_rate': 0.08722639394105904, 'depth': 3, 'l2_leaf_reg': 0.013014470320306191}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:11:53,331] Trial 213 finished with value: 0.3765091675538547 and parameters: {'learning_rate': 0.08914930524243143, 'depth': 3, 'l2_leaf_reg': 0.37524594746059525}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:12:36,399] Trial 214 finished with value: 0.3790585829137849 and parameters: {'learning_rate': 0.09162775050711218, 'depth': 3, 'l2_leaf_reg': 0.01617271565871316}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:13:21,741] Trial 215 finished with value: 0.3788902609731319 and parameters: {'learning_rate': 0.09354614466070642, 'depth': 3, 'l2_leaf_reg': 0.027134042788721557}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:14:08,433] Trial 216 finished with value: 0.37774789936450265 and parameters: {'learning_rate': 0.09020725675075007, 'depth': 3, 'l2_leaf_reg': 0.010262833048342725}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:14:54,849] Trial 217 finished with value: 0.3782042616578195 and parameters: {'learning_rate': 0.09521059186166494, 'depth': 3, 'l2_leaf_reg': 0.02127647293003623}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:15:39,324] Trial 218 finished with value: 0.377835165887012 and parameters: {'learning_rate': 0.08735843665014681, 'depth': 3, 'l2_leaf_reg': 0.0038976870617613655}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:16:18,386] Trial 219 finished with value: 0.37294781894059326 and parameters: {'learning_rate': 0.09234571817716243, 'depth': 8, 'l2_leaf_reg': 0.005716960068647808}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:17:05,806] Trial 220 finished with value: 0.3766113292977813 and parameters: {'learning_rate': 0.09783110921120812, 'depth': 3, 'l2_leaf_reg': 0.008359761947126223}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:17:55,390] Trial 221 finished with value: 0.37654158823388645 and parameters: {'learning_rate': 0.0965796806046739, 'depth': 3, 'l2_leaf_reg': 0.03310548924292716}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:18:44,393] Trial 222 finished with value: 0.37746848316742593 and parameters: {'learning_rate': 0.09446176505408219, 'depth': 3, 'l2_leaf_reg': 0.018418949960376144}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:19:26,723] Trial 223 finished with value: 0.37777734649922945 and parameters: {'learning_rate': 0.09882921820975187, 'depth': 3, 'l2_leaf_reg': 0.026989019340792137}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:20:12,394] Trial 224 finished with value: 0.37970605715189465 and parameters: {'learning_rate': 0.08894562638673972, 'depth': 3, 'l2_leaf_reg': 0.014473884070524044}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:21:01,896] Trial 225 finished with value: 0.37847655567435196 and parameters: {'learning_rate': 0.09129961807562931, 'depth': 3, 'l2_leaf_reg': 0.02020255206767119}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:21:46,488] Trial 226 finished with value: 0.3812501617787984 and parameters: {'learning_rate': 0.09676499478361746, 'depth': 3, 'l2_leaf_reg': 0.0400102774390124}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:22:27,818] Trial 227 finished with value: 0.3784094394959991 and parameters: {'learning_rate': 0.09294509510348871, 'depth': 3, 'l2_leaf_reg': 0.04641969820342151}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:23:10,120] Trial 228 finished with value: 0.3786772798022539 and parameters: {'learning_rate': 0.0966092875117319, 'depth': 3, 'l2_leaf_reg': 0.012338121421117641}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:23:54,027] Trial 229 finished with value: 0.3780637462263958 and parameters: {'learning_rate': 0.09980607982566617, 'depth': 3, 'l2_leaf_reg': 0.036729425135344246}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:24:39,237] Trial 230 finished with value: 0.378710210322911 and parameters: {'learning_rate': 0.0953502355043165, 'depth': 3, 'l2_leaf_reg': 0.29841970951549895}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:25:22,999] Trial 231 finished with value: 0.3780198215310747 and parameters: {'learning_rate': 0.0978036998238667, 'depth': 3, 'l2_leaf_reg': 0.027281012226639933}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:26:09,189] Trial 232 finished with value: 0.37945241316629824 and parameters: {'learning_rate': 0.09037711372914146, 'depth': 3, 'l2_leaf_reg': 0.05350555081417596}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:27:03,522] Trial 233 finished with value: 0.38146402256157474 and parameters: {'learning_rate': 0.09422101516248127, 'depth': 3, 'l2_leaf_reg': 0.022346680632996767}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:27:54,131] Trial 234 finished with value: 0.37811190063709077 and parameters: {'learning_rate': 0.09367063038383669, 'depth': 3, 'l2_leaf_reg': 0.016512810790035366}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:28:46,498] Trial 235 finished with value: 0.3773740206166476 and parameters: {'learning_rate': 0.08832171685191793, 'depth': 3, 'l2_leaf_reg': 0.02397845029742959}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:29:35,290] Trial 236 finished with value: 0.3798928714040034 and parameters: {'learning_rate': 0.08551521222879152, 'depth': 3, 'l2_leaf_reg': 0.020539417563431105}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:30:26,290] Trial 237 finished with value: 0.3777846190725366 and parameters: {'learning_rate': 0.09177961011556593, 'depth': 3, 'l2_leaf_reg': 0.09518863684193551}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:31:03,211] Trial 238 finished with value: 0.3769538031897398 and parameters: {'learning_rate': 0.09479560242177629, 'depth': 3, 'l2_leaf_reg': 0.035005595493362976}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:31:43,322] Trial 239 finished with value: 0.37767648514916086 and parameters: {'learning_rate': 0.09991605010944885, 'depth': 3, 'l2_leaf_reg': 0.014344063707605608}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:32:25,460] Trial 240 finished with value: 0.37941937190082464 and parameters: {'learning_rate': 0.09002540568055402, 'depth': 3, 'l2_leaf_reg': 0.011361145563550811}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:32:59,423] Trial 241 finished with value: 0.3771571400028603 and parameters: {'learning_rate': 0.0978338739793705, 'depth': 3, 'l2_leaf_reg': 0.029575456221525073}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:33:32,834] Trial 242 finished with value: 0.3751670374444932 and parameters: {'learning_rate': 0.0960213265930211, 'depth': 3, 'l2_leaf_reg': 0.043074968121038705}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:34:05,841] Trial 243 finished with value: 0.3795052300805269 and parameters: {'learning_rate': 0.09261333638654122, 'depth': 3, 'l2_leaf_reg': 0.02114469883027941}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:34:40,370] Trial 244 finished with value: 0.37639025336271653 and parameters: {'learning_rate': 0.09632893966043263, 'depth': 3, 'l2_leaf_reg': 0.017641246157508495}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:35:13,684] Trial 245 finished with value: 0.37797293725107484 and parameters: {'learning_rate': 0.09777007662673964, 'depth': 3, 'l2_leaf_reg': 0.027262345829161615}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:35:52,690] Trial 246 finished with value: 0.3816318379687743 and parameters: {'learning_rate': 0.0942074610364229, 'depth': 3, 'l2_leaf_reg': 0.02262443859997675}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:36:27,690] Trial 247 finished with value: 0.3767542325094427 and parameters: {'learning_rate': 0.09379479224256157, 'depth': 3, 'l2_leaf_reg': 0.016304182588522453}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:37:09,318] Trial 248 finished with value: 0.3786315503488301 and parameters: {'learning_rate': 0.09082743636363162, 'depth': 3, 'l2_leaf_reg': 0.020734281453826043}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:38:15,024] Trial 249 finished with value: 0.3750470901363294 and parameters: {'learning_rate': 0.050390804680811196, 'depth': 3, 'l2_leaf_reg': 0.01355662398987391}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:38:54,590] Trial 250 finished with value: 0.3795559443514157 and parameters: {'learning_rate': 0.0877833800690298, 'depth': 3, 'l2_leaf_reg': 0.02387555428166661}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:39:34,832] Trial 251 finished with value: 0.379112492765757 and parameters: {'learning_rate': 0.09207624253480189, 'depth': 3, 'l2_leaf_reg': 0.07317607100846507}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:40:10,686] Trial 252 finished with value: 0.3790777154074578 and parameters: {'learning_rate': 0.08893982331017898, 'depth': 3, 'l2_leaf_reg': 0.032124394535044606}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:40:50,714] Trial 253 finished with value: 0.37753007660726945 and parameters: {'learning_rate': 0.0949074562750559, 'depth': 3, 'l2_leaf_reg': 0.1922882399497828}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:41:27,022] Trial 254 finished with value: 0.3787889021721515 and parameters: {'learning_rate': 0.09326723791315332, 'depth': 3, 'l2_leaf_reg': 0.1501109221969291}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:42:02,308] Trial 255 finished with value: 0.38159167374111747 and parameters: {'learning_rate': 0.09099690675949326, 'depth': 3, 'l2_leaf_reg': 0.017749181003040317}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:42:39,402] Trial 256 finished with value: 0.3800667279613762 and parameters: {'learning_rate': 0.09107302297312907, 'depth': 3, 'l2_leaf_reg': 0.01755820799189746}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:43:14,883] Trial 257 finished with value: 0.37952015525816796 and parameters: {'learning_rate': 0.09094557765198251, 'depth': 3, 'l2_leaf_reg': 0.017469671435466117}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:43:52,200] Trial 258 finished with value: 0.37744855392248666 and parameters: {'learning_rate': 0.09229907935901668, 'depth': 3, 'l2_leaf_reg': 0.01301605107815877}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:44:37,778] Trial 259 finished with value: 0.3799537021604503 and parameters: {'learning_rate': 0.08921058984490382, 'depth': 3, 'l2_leaf_reg': 0.022607012522635736}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:45:21,466] Trial 260 finished with value: 0.37785539776487764 and parameters: {'learning_rate': 0.08628478651366306, 'depth': 3, 'l2_leaf_reg': 0.015208401808981725}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:45:57,819] Trial 261 finished with value: 0.3788442504992414 and parameters: {'learning_rate': 0.09455793347426061, 'depth': 3, 'l2_leaf_reg': 0.01911242658052636}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:46:33,988] Trial 262 finished with value: 0.3812942082889893 and parameters: {'learning_rate': 0.09057003354951945, 'depth': 3, 'l2_leaf_reg': 0.011189061566915709}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:47:10,458] Trial 263 finished with value: 0.3793062167950133 and parameters: {'learning_rate': 0.09174716860210828, 'depth': 3, 'l2_leaf_reg': 0.010662108250592502}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:47:47,012] Trial 264 finished with value: 0.3785975238914945 and parameters: {'learning_rate': 0.09355467302222059, 'depth': 3, 'l2_leaf_reg': 0.011611312924643478}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:48:27,016] Trial 265 finished with value: 0.3794219570281031 and parameters: {'learning_rate': 0.08808207277995134, 'depth': 3, 'l2_leaf_reg': 0.04124450092030574}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:49:02,105] Trial 266 finished with value: 0.3785564041850397 and parameters: {'learning_rate': 0.09055508112219145, 'depth': 3, 'l2_leaf_reg': 0.024239855295641422}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:51:53,177] Trial 267 finished with value: 0.3775529528973444 and parameters: {'learning_rate': 0.012556713070096717, 'depth': 3, 'l2_leaf_reg': 0.014112516103479864}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:52:25,765] Trial 268 finished with value: 0.37832883987699945 and parameters: {'learning_rate': 0.09602617836054321, 'depth': 3, 'l2_leaf_reg': 0.018902609108002583}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:52:58,881] Trial 269 finished with value: 0.3774404807652562 and parameters: {'learning_rate': 0.09315163104259536, 'depth': 3, 'l2_leaf_reg': 0.008934493055605256}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:53:34,765] Trial 270 finished with value: 0.3809324292383553 and parameters: {'learning_rate': 0.08388950606724867, 'depth': 3, 'l2_leaf_reg': 0.0319840253364947}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:54:05,504] Trial 271 finished with value: 0.37663496375036865 and parameters: {'learning_rate': 0.08506120811988055, 'depth': 4, 'l2_leaf_reg': 0.0351377917319974}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:54:44,384] Trial 272 finished with value: 0.37537559111283564 and parameters: {'learning_rate': 0.08696269028003763, 'depth': 3, 'l2_leaf_reg': 0.029411234518653292}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:55:15,892] Trial 273 finished with value: 0.3771340291350043 and parameters: {'learning_rate': 0.09711424610812029, 'depth': 3, 'l2_leaf_reg': 0.025186200388794332}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:55:56,110] Trial 274 finished with value: 0.379381304122524 and parameters: {'learning_rate': 0.09474948557582143, 'depth': 3, 'l2_leaf_reg': 0.056917616087998696}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:56:23,761] Trial 275 finished with value: 0.3733256213617897 and parameters: {'learning_rate': 0.08887084038886493, 'depth': 6, 'l2_leaf_reg': 0.0406190086988031}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:57:03,882] Trial 276 finished with value: 0.37557409647818635 and parameters: {'learning_rate': 0.08312381321990091, 'depth': 3, 'l2_leaf_reg': 0.03173475441371382}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:57:42,669] Trial 277 finished with value: 0.37725082157606193 and parameters: {'learning_rate': 0.09176489155829708, 'depth': 3, 'l2_leaf_reg': 0.02109020067047325}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:58:18,506] Trial 278 finished with value: 0.378744467698095 and parameters: {'learning_rate': 0.08760945094424395, 'depth': 3, 'l2_leaf_reg': 0.04964293957667003}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:58:51,592] Trial 279 finished with value: 0.37636970835523537 and parameters: {'learning_rate': 0.09833599774822702, 'depth': 3, 'l2_leaf_reg': 0.1298592330934686}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 01:59:23,785] Trial 280 finished with value: 0.37674322905548036 and parameters: {'learning_rate': 0.09628351960751777, 'depth': 3, 'l2_leaf_reg': 0.02622045585069228}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:00:57,561] Trial 281 finished with value: 0.37709278756667797 and parameters: {'learning_rate': 0.02578712870664896, 'depth': 3, 'l2_leaf_reg': 0.015986829467099496}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:01:32,661] Trial 282 finished with value: 0.37741602154710485 and parameters: {'learning_rate': 0.09035338003890069, 'depth': 3, 'l2_leaf_reg': 0.0197097806724469}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:02:14,768] Trial 283 finished with value: 0.3772546878311135 and parameters: {'learning_rate': 0.07786563529012769, 'depth': 3, 'l2_leaf_reg': 0.029936370418526852}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:02:51,668] Trial 284 finished with value: 0.37892753223612 and parameters: {'learning_rate': 0.09406438254711823, 'depth': 3, 'l2_leaf_reg': 0.035884439086976604}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:03:38,133] Trial 285 finished with value: 0.3793889110449463 and parameters: {'learning_rate': 0.08623376523754947, 'depth': 3, 'l2_leaf_reg': 0.23239928543830207}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:04:12,260] Trial 286 finished with value: 0.3790213498103853 and parameters: {'learning_rate': 0.09999413116007945, 'depth': 5, 'l2_leaf_reg': 1.8443147772895108}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:04:52,315] Trial 287 finished with value: 0.3781561235374066 and parameters: {'learning_rate': 0.09219183815037876, 'depth': 3, 'l2_leaf_reg': 0.0224512790839834}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:05:34,117] Trial 288 finished with value: 0.3774829436156388 and parameters: {'learning_rate': 0.0956020308015902, 'depth': 3, 'l2_leaf_reg': 0.01857192746722893}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:06:16,662] Trial 289 finished with value: 0.37680357902093775 and parameters: {'learning_rate': 0.08908122672117953, 'depth': 3, 'l2_leaf_reg': 0.014287497242461656}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:06:49,716] Trial 290 finished with value: 0.37664651653191034 and parameters: {'learning_rate': 0.09750950935714489, 'depth': 3, 'l2_leaf_reg': 0.016211577959907846}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:07:35,790] Trial 291 finished with value: 0.3695198124689208 and parameters: {'learning_rate': 0.09099299821879081, 'depth': 9, 'l2_leaf_reg': 0.024263510300546215}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:08:17,053] Trial 292 finished with value: 0.37670577282615564 and parameters: {'learning_rate': 0.09338969321861598, 'depth': 3, 'l2_leaf_reg': 0.012681722006823774}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:09:06,958] Trial 293 finished with value: 0.3783939536006438 and parameters: {'learning_rate': 0.08358226234273923, 'depth': 3, 'l2_leaf_reg': 0.06495351261439015}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:09:45,319] Trial 294 finished with value: 0.3787921915276643 and parameters: {'learning_rate': 0.09530734917321954, 'depth': 4, 'l2_leaf_reg': 0.02864443467928928}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:10:23,312] Trial 295 finished with value: 0.37880112958656226 and parameters: {'learning_rate': 0.08990524521424385, 'depth': 3, 'l2_leaf_reg': 0.0010934812680239193}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:10:51,560] Trial 296 finished with value: 0.3728364937255038 and parameters: {'learning_rate': 0.09815481895675925, 'depth': 7, 'l2_leaf_reg': 0.042435868753197326}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:11:30,816] Trial 297 finished with value: 0.37722419260994833 and parameters: {'learning_rate': 0.09235568651322909, 'depth': 3, 'l2_leaf_reg': 0.02055075979122682}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:12:13,207] Trial 298 finished with value: 0.3793837448874141 and parameters: {'learning_rate': 0.08697106704929848, 'depth': 3, 'l2_leaf_reg': 0.016021343986726336}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:12:54,835] Trial 299 finished with value: 0.38016971088095575 and parameters: {'learning_rate': 0.09446967658848268, 'depth': 3, 'l2_leaf_reg': 0.025308563670198337}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:13:24,023] Trial 300 finished with value: 0.37723469492398765 and parameters: {'learning_rate': 0.09451258656599479, 'depth': 4, 'l2_leaf_reg': 0.02447779017565449}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:14:07,767] Trial 301 finished with value: 0.37754792855144637 and parameters: {'learning_rate': 0.09666142848273644, 'depth': 3, 'l2_leaf_reg': 0.019862376108912692}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:14:44,796] Trial 302 finished with value: 0.37683463905944414 and parameters: {'learning_rate': 0.09996358312030523, 'depth': 3, 'l2_leaf_reg': 0.01703120587285943}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:15:26,748] Trial 303 finished with value: 0.3792447061037179 and parameters: {'learning_rate': 0.0936253407476216, 'depth': 3, 'l2_leaf_reg': 0.03325984762026211}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:16:07,085] Trial 304 finished with value: 0.3807746164482034 and parameters: {'learning_rate': 0.09819964911356131, 'depth': 3, 'l2_leaf_reg': 0.012830329197878484}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:16:48,744] Trial 305 finished with value: 0.37876831922950505 and parameters: {'learning_rate': 0.09826098091645406, 'depth': 3, 'l2_leaf_reg': 0.012263819283380786}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:17:27,526] Trial 306 finished with value: 0.3791899607256205 and parameters: {'learning_rate': 0.09707627310045187, 'depth': 3, 'l2_leaf_reg': 0.009848996265441268}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:18:08,947] Trial 307 finished with value: 0.3789671248056435 and parameters: {'learning_rate': 0.09602659733411716, 'depth': 3, 'l2_leaf_reg': 0.17582380569265377}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:18:48,615] Trial 308 finished with value: 0.3774141201490745 and parameters: {'learning_rate': 0.09855488441626147, 'depth': 3, 'l2_leaf_reg': 0.026413543265193896}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:19:24,172] Trial 309 finished with value: 0.3799957582669168 and parameters: {'learning_rate': 0.09513338042433729, 'depth': 3, 'l2_leaf_reg': 0.01238541895229539}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:20:01,553] Trial 310 finished with value: 0.3773661190217549 and parameters: {'learning_rate': 0.09825385633842187, 'depth': 3, 'l2_leaf_reg': 0.014312035720966816}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:20:33,940] Trial 311 finished with value: 0.3706182328855919 and parameters: {'learning_rate': 0.09607090641962496, 'depth': 8, 'l2_leaf_reg': 0.021219869355666318}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:21:35,352] Trial 312 finished with value: 0.37855872324192635 and parameters: {'learning_rate': 0.05568192985985505, 'depth': 3, 'l2_leaf_reg': 0.009287417156051974}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:22:16,361] Trial 313 finished with value: 0.3769559445384134 and parameters: {'learning_rate': 0.09295633525113328, 'depth': 3, 'l2_leaf_reg': 3.3775375582916984}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:23:06,505] Trial 314 finished with value: 0.3789644692684595 and parameters: {'learning_rate': 0.08505124462140148, 'depth': 3, 'l2_leaf_reg': 1.3641093639951027}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:23:45,784] Trial 315 finished with value: 0.37983199151316743 and parameters: {'learning_rate': 0.09428186641904776, 'depth': 3, 'l2_leaf_reg': 0.029941439538922813}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:24:26,466] Trial 316 finished with value: 0.378745129376037 and parameters: {'learning_rate': 0.09837717777514392, 'depth': 3, 'l2_leaf_reg': 0.10877449891825101}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:25:06,600] Trial 317 finished with value: 0.37653740862579477 and parameters: {'learning_rate': 0.08885061229130962, 'depth': 3, 'l2_leaf_reg': 0.015038563230922609}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:25:50,395] Trial 318 finished with value: 0.37725782869151203 and parameters: {'learning_rate': 0.0964256411120767, 'depth': 3, 'l2_leaf_reg': 0.022855144496984864}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:26:32,793] Trial 319 finished with value: 0.3771910316379491 and parameters: {'learning_rate': 0.0997032093468672, 'depth': 3, 'l2_leaf_reg': 0.017946884164750848}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:27:12,789] Trial 320 finished with value: 0.3768604964365469 and parameters: {'learning_rate': 0.09251816235345488, 'depth': 3, 'l2_leaf_reg': 0.0363078294652102}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:27:47,274] Trial 321 finished with value: 0.3796789814585882 and parameters: {'learning_rate': 0.09417844640377525, 'depth': 3, 'l2_leaf_reg': 0.01073247899502018}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:28:46,474] Trial 322 finished with value: 0.3750977804026775 and parameters: {'learning_rate': 0.033282646336295886, 'depth': 4, 'l2_leaf_reg': 0.026365229807084948}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:29:22,815] Trial 323 finished with value: 0.3782694003602871 and parameters: {'learning_rate': 0.08753169281965051, 'depth': 3, 'l2_leaf_reg': 0.2853657714072457}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:29:55,356] Trial 324 finished with value: 0.3768645093093724 and parameters: {'learning_rate': 0.09706451353086555, 'depth': 3, 'l2_leaf_reg': 0.008156755848221972}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:30:34,861] Trial 325 finished with value: 0.3745647793466252 and parameters: {'learning_rate': 0.0636229583704424, 'depth': 3, 'l2_leaf_reg': 0.014134986618748962}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:31:14,945] Trial 326 finished with value: 0.3797240399378795 and parameters: {'learning_rate': 0.09028651746175574, 'depth': 3, 'l2_leaf_reg': 0.021759020980533172}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:31:45,751] Trial 327 finished with value: 0.37676568203029875 and parameters: {'learning_rate': 0.09210434470430442, 'depth': 3, 'l2_leaf_reg': 0.01806835865706686}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:32:23,114] Trial 328 finished with value: 0.37844497729209003 and parameters: {'learning_rate': 0.09588414752226947, 'depth': 3, 'l2_leaf_reg': 0.032488765950041264}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:33:05,190] Trial 329 finished with value: 0.38018499293656827 and parameters: {'learning_rate': 0.0881965024283943, 'depth': 3, 'l2_leaf_reg': 0.011799225595123489}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:33:40,890] Trial 330 finished with value: 0.37853020365516393 and parameters: {'learning_rate': 0.0863574652490681, 'depth': 3, 'l2_leaf_reg': 0.01189544166336018}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:34:20,731] Trial 331 finished with value: 0.3791761736955518 and parameters: {'learning_rate': 0.08426044198818486, 'depth': 3, 'l2_leaf_reg': 0.007082808476226387}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:35:00,166] Trial 332 finished with value: 0.37887261953729756 and parameters: {'learning_rate': 0.08786771238750363, 'depth': 3, 'l2_leaf_reg': 0.009589819855540435}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:35:37,291] Trial 333 finished with value: 0.3809849762108014 and parameters: {'learning_rate': 0.08972026900212222, 'depth': 3, 'l2_leaf_reg': 0.013553135900525027}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:36:16,615] Trial 334 finished with value: 0.3797406431020634 and parameters: {'learning_rate': 0.08972094574709548, 'depth': 3, 'l2_leaf_reg': 0.0153958850989527}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:37:13,289] Trial 335 finished with value: 0.3676195024416119 and parameters: {'learning_rate': 0.09111545579767145, 'depth': 10, 'l2_leaf_reg': 0.013596837858199694}. Best is trial 181 with value: 0.3817964812636329.\n",
      "[I 2025-05-07 02:37:54,480] Trial 336 finished with value: 0.38272329859193543 and parameters: {'learning_rate': 0.0894488970066411, 'depth': 3, 'l2_leaf_reg': 0.04861123719686134}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:38:30,549] Trial 337 finished with value: 0.3801271765283368 and parameters: {'learning_rate': 0.08900349569842494, 'depth': 3, 'l2_leaf_reg': 0.41890497072769595}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:39:10,635] Trial 338 finished with value: 0.37950603674889016 and parameters: {'learning_rate': 0.08991657432816746, 'depth': 3, 'l2_leaf_reg': 0.05220697968558575}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:39:51,736] Trial 339 finished with value: 0.37944389170251547 and parameters: {'learning_rate': 0.08544285144343806, 'depth': 3, 'l2_leaf_reg': 0.017605703262885703}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:40:25,352] Trial 340 finished with value: 0.3785558602937506 and parameters: {'learning_rate': 0.08651263178957694, 'depth': 3, 'l2_leaf_reg': 0.010913064869347141}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:40:59,205] Trial 341 finished with value: 0.37714156892716694 and parameters: {'learning_rate': 0.09163175632936046, 'depth': 3, 'l2_leaf_reg': 0.014743717557502905}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:41:29,068] Trial 342 finished with value: 0.37678469214599913 and parameters: {'learning_rate': 0.08836728852265904, 'depth': 4, 'l2_leaf_reg': 0.02017501865669547}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:42:06,661] Trial 343 finished with value: 0.3762706560635113 and parameters: {'learning_rate': 0.08178353770678708, 'depth': 3, 'l2_leaf_reg': 0.04195674685226565}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:42:38,899] Trial 344 finished with value: 0.37737300458755046 and parameters: {'learning_rate': 0.09248002489395774, 'depth': 3, 'l2_leaf_reg': 0.016016304074212874}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:43:15,607] Trial 345 finished with value: 0.378223902235562 and parameters: {'learning_rate': 0.09037625224242535, 'depth': 3, 'l2_leaf_reg': 0.023573692969706586}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:43:56,370] Trial 346 finished with value: 0.37831365781824833 and parameters: {'learning_rate': 0.08872387541495595, 'depth': 3, 'l2_leaf_reg': 0.22198644005582366}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:44:32,749] Trial 347 finished with value: 0.37943273798618815 and parameters: {'learning_rate': 0.09337600786725132, 'depth': 3, 'l2_leaf_reg': 1.0434686772262391}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:45:11,345] Trial 348 finished with value: 0.37906209386189893 and parameters: {'learning_rate': 0.08702376757796611, 'depth': 3, 'l2_leaf_reg': 0.012835465658022432}. Best is trial 336 with value: 0.38272329859193543.\n",
      "[I 2025-05-07 02:45:49,917] Trial 349 finished with value: 0.3783915282702917 and parameters: {'learning_rate': 0.09782226028193276, 'depth': 3, 'l2_leaf_reg': 0.03042639187202675}. Best is trial 336 with value: 0.38272329859193543.\n"
     ]
    }
   ],
   "source": [
    "presence_info_df_3 = pd.read_csv('logs/subset_info_3.csv')\n",
    "# Run Optuna\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(lambda trial: objective(trial, train_df, presence_info_df_3, target, kfoldcv= 5),\n",
    "                n_trials=350)\n",
    "\n",
    "\n",
    "best_f1 = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd45e6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1:\n",
      "  Value: 0.38272329859193543\n",
      "  Params: {'learning_rate': 0.0894488970066411, 'depth': 3, 'l2_leaf_reg': 0.04861123719686134}\n",
      "Top 2:\n",
      "  Value: 0.3817964812636329\n",
      "  Params: {'learning_rate': 0.08943465486972843, 'depth': 3, 'l2_leaf_reg': 0.01622233983575132}\n",
      "Top 3:\n",
      "  Value: 0.3816318379687743\n",
      "  Params: {'learning_rate': 0.0942074610364229, 'depth': 3, 'l2_leaf_reg': 0.02262443859997675}\n",
      "Top 4:\n",
      "  Value: 0.3816004692220901\n",
      "  Params: {'learning_rate': 0.09930570612937266, 'depth': 3, 'l2_leaf_reg': 0.020862748392985343}\n",
      "Top 5:\n",
      "  Value: 0.38159167374111747\n",
      "  Params: {'learning_rate': 0.09099690675949326, 'depth': 3, 'l2_leaf_reg': 0.017749181003040317}\n"
     ]
    }
   ],
   "source": [
    "top_trials = sorted(study.trials, key=lambda t: t.value, reverse=True)[:5]  # For minimization\n",
    "# or reverse=True if you're maximizing\n",
    "\n",
    "# Print parameters of top trials\n",
    "for i, trial in enumerate(top_trials, 1):\n",
    "    print(f\"Top {i}:\")\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(f\"  Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b7a6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference_min, info_min = study.best_trial.user_attrs['difference_min'], study.best_trial.user_attrs['info_min']\n",
    "difference_min, info_min = 0.05, 0.03\n",
    "\n",
    "presence_info_df_3 = presence_info_df_3[(np.abs(presence_info_df_3['difference']) > difference_min) & (presence_info_df_3['info'] > info_min)]\n",
    "presence_info_df = presence_info_df_3\n",
    "\n",
    "updated_train_df = add_presence_columns(train_df, presence_info_df)\n",
    "updated_test_df = add_presence_columns(test_df, presence_info_df)\n",
    "\n",
    "present_cols = [col for col in updated_train_df.columns if col.endswith('_present')]\n",
    "# print(updated_train_df[non_present_cols].info())\n",
    "\n",
    "\n",
    "high_dim_cat_cols_to_drop = ['claim_date.day', 'claim_date.dayofweek', 'claim_date.weekofyear', 'claim_date.month', 'zero_payout']\n",
    "updated_train_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True)\n",
    "updated_test_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True)\n",
    "\n",
    "# Step 1: Fit on training data\n",
    "onehot, scaler, cat_cols, num_cols = fit_regular_transformer(updated_train_df)\n",
    "\n",
    "# Step 2: Transform training set itself\n",
    "X_train_regular = transform_regular_set(updated_train_df, onehot, scaler, cat_cols, num_cols)\n",
    "\n",
    "# Step 3: Transform test set (call the same function on test_df)\n",
    "X_test_regular = transform_regular_set(test_df, onehot, scaler, cat_cols, num_cols)\n",
    "\n",
    "# present_cols = []\n",
    "# Combine for train\n",
    "updated_train_final = pd.concat([X_train_regular, updated_train_df[present_cols]], axis=1)\n",
    "\n",
    "# Combine for test\n",
    "updated_test_final = pd.concat([X_test_regular, updated_test_df[present_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d823465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train DataFrame to ../Records/ctb_temp\\train_2025.csv\n",
      "Saved test DataFrame to ../Records/ctb_temp\\test_2025.csv\n",
      "Saved best parameters to ../Records/ctb_temp\\param_ctb_temp.json\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "import json\n",
    "output_dir = '../Records/ctb_temp'\n",
    "train_csv_path = os.path.join(output_dir, 'train_2025.csv')\n",
    "test_csv_path = os.path.join(output_dir, 'test_2025.csv')\n",
    "param_json_path = os.path.join(output_dir, 'param_ctb_temp.json')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save DataFrames\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "print(f\"Saved train DataFrame to {train_csv_path}\")\n",
    "\n",
    "test_df.to_csv(test_csv_path, index=False)\n",
    "print(f\"Saved test DataFrame to {test_csv_path}\")\n",
    "\n",
    "# Save best_params as JSON\n",
    "best_threshold = study.best_trial.user_attrs['mean_threshold']\n",
    "best_params = study.best_params\n",
    "best_params.update({'mean_threshold': float(best_threshold)})\n",
    "with open(param_json_path, 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "print(f\"Saved best parameters to {param_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "205ca36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6394335\ttest: 0.6386021\tbest: 0.6386021 (0)\ttotal: 26.2ms\tremaining: 2m 11s\n",
      "100:\tlearn: 0.3910573\ttest: 0.3905850\tbest: 0.3905548 (99)\ttotal: 2.58s\tremaining: 2m 5s\n",
      "200:\tlearn: 0.3836591\ttest: 0.3858616\tbest: 0.3857296 (194)\ttotal: 5.12s\tremaining: 2m 2s\n",
      "300:\tlearn: 0.3803340\ttest: 0.3815168\tbest: 0.3815112 (299)\ttotal: 7.67s\tremaining: 1m 59s\n",
      "400:\tlearn: 0.3760277\ttest: 0.3835581\tbest: 0.3812479 (305)\ttotal: 10.2s\tremaining: 1m 57s\n",
      "bestTest = 0.3812479231\n",
      "bestIteration = 305\n",
      "Shrink model to first 306 iterations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split train into final train and validation sets\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "    updated_train_final, target, test_size=0.01, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare CatBoost parameters (matching what you used before)\n",
    "cat_params = {\n",
    "    'iterations': 5000,\n",
    "    'learning_rate': best_params.get('learning_rate', 0.05),  # fallback value if not in best_params\n",
    "    'depth': best_params.get('depth', 6),\n",
    "    'l2_leaf_reg': best_params.get('l2_leaf_reg', 3.0),\n",
    "    'random_seed': 69,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'verbose': 100,          # adjust or set False for silent\n",
    "    'early_stopping_rounds': 100,\n",
    "    'task_type': 'GPU'       # or 'CPU' if needed\n",
    "}\n",
    "\n",
    "# Set up Pools\n",
    "train_pool = Pool(X_train_final, y_train_final)\n",
    "val_pool = Pool(X_val_final, y_val_final)\n",
    "test_pool = Pool(updated_test_final)\n",
    "\n",
    "# Initialize and train CatBoost model\n",
    "final_model = CatBoostClassifier(**cat_params)\n",
    "final_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    verbose=100,  # or False for silent\n",
    ")\n",
    "\n",
    "# Predict on test set (probabilities)\n",
    "probs_test = final_model.predict_proba(test_pool)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3dfa6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%m%d_%H%M')\n",
    "\n",
    "final_preds = (probs_test > best_threshold).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'claim_number': test_id,\n",
    "    'fraud': final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(f'../Submit/submission_ctb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
