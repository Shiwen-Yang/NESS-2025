{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfe1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yangs\\.conda\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "from scipy.stats import skew, kurtosis\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize']=10,20\n",
    "\n",
    "# Add the grandparent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "from Utils import FE_helper as FE\n",
    "from Utils import training_models as TM\n",
    "from tqdm import tqdm \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669be49",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc8d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the data\n",
    "train_df = pd.read_csv('../Original_Data/train_2025.csv') \n",
    "test_df = pd.read_csv('../Original_Data/test_2025.csv')\n",
    "\n",
    "train_df = FE.add_features(train_df)\n",
    "test_df = FE.add_features(test_df)\n",
    "\n",
    "test_id = test_df['claim_number']\n",
    "train_id = train_df['claim_number']\n",
    "target = train_df['fraud']\n",
    "\n",
    "ignore_var = ['claim_date.is_weekend', 'claim_date.near_holiday', 'fraud']\n",
    "train_df = FE.drop_ignored_columns(train_df, ignore_var)\n",
    "test_df = FE.drop_ignored_columns(test_df, ignore_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c511dc",
   "metadata": {},
   "source": [
    "# Preprocessing Data. Training and Testing Data Needs To Be Fully Numerical Before Proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56718a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_df = train_df\n",
    "updated_test_df = test_df\n",
    "\n",
    "high_dim_cat_cols_to_drop = ['claim_date.day', 'claim_date.dayofweek', 'claim_date.weekofyear', 'claim_date.month']\n",
    "updated_train_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True, errors='ignore')\n",
    "updated_test_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Step 1: Fit on training data\n",
    "onehot, scaler, cat_cols, num_cols = FE.fit_regular_transformer(updated_train_df, '_count')\n",
    "\n",
    "# Step 2: Transform training set itself\n",
    "X_train_regular = FE.transform_regular_set(updated_train_df, onehot, scaler, cat_cols, num_cols)\n",
    "\n",
    "# Step 3: Transform test set (call the same function on test_df)\n",
    "X_test_regular = FE.transform_regular_set(updated_test_df, onehot, scaler, cat_cols, num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c88c6",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a30ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['lgb', 'xgb', 'cat', 'hgb']\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "#################### CHANGE THIS NUMBER TO SWAP MODEL ####################\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "model_name= models_list[1] \n",
    "output_dir = f'../Records/{model_name}_temp'\n",
    "\n",
    "train_model_fn = getattr(TM, f\"train_{model_name}\", None)\n",
    "params_trial_fn= getattr(TM, f\"sample_{model_name}_hyperparams\", None)\n",
    "predict_fn = getattr(TM, f\"predict_{model_name}\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eff47e",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning For the Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa7c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 15:43:59,833] A new study created in memory with name: no-name-ce071b12-c13f-49e1-b3bb-afa048930682\n",
      "[I 2025-05-14 15:44:16,826] Trial 0 finished with value: 0.36877925575905457 and parameters: {'max_depth': 11, 'min_child_weight': 0.02764399638270855, 'subsample': 0.5691649803200671, 'colsample_bytree': 0.8098193289437603, 'learning_rate': 0.009175918787334397, 'lambda': 0.015968145536887447, 'alpha': 11.129521797667902, 'scale_pos_weight': 1.0}. Best is trial 0 with value: 0.36877925575905457.\n",
      "[I 2025-05-14 15:44:29,789] Trial 1 finished with value: 0.36251426011275983 and parameters: {'max_depth': 10, 'min_child_weight': 0.10529661566060684, 'subsample': 0.3297941606080186, 'colsample_bytree': 0.41199456708957904, 'learning_rate': 0.013908195380703411, 'lambda': 0.4257748249819686, 'alpha': 0.38008867775749106, 'scale_pos_weight': 1.0}. Best is trial 0 with value: 0.36877925575905457.\n",
      "[I 2025-05-14 15:44:35,725] Trial 2 finished with value: 0.36827806126666857 and parameters: {'max_depth': 7, 'min_child_weight': 0.9501644842262452, 'subsample': 0.5449659708188077, 'colsample_bytree': 0.830397725276995, 'learning_rate': 0.029800121444328677, 'lambda': 0.020246762501841944, 'alpha': 0.011017657657903723, 'scale_pos_weight': 1.0}. Best is trial 0 with value: 0.36877925575905457.\n",
      "[I 2025-05-14 15:44:41,085] Trial 3 finished with value: 0.37357116559590164 and parameters: {'max_depth': 10, 'min_child_weight': 0.018965603438630498, 'subsample': 0.6000937970271516, 'colsample_bytree': 0.6930565371630498, 'learning_rate': 0.09611056373161989, 'lambda': 5.13345088515268, 'alpha': 11.890045789235543, 'scale_pos_weight': 1.0}. Best is trial 3 with value: 0.37357116559590164.\n",
      "[I 2025-05-14 15:44:44,958] Trial 4 finished with value: 0.36810543614178404 and parameters: {'max_depth': 5, 'min_child_weight': 0.13417838038024543, 'subsample': 0.40372032391280094, 'colsample_bytree': 0.5904457805942354, 'learning_rate': 0.07948311971176238, 'lambda': 0.01479531372437674, 'alpha': 0.02300844844222373, 'scale_pos_weight': 1.0}. Best is trial 3 with value: 0.37357116559590164.\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(lambda trial: TM.objective_single_model(trial=trial, \n",
    "                                       full_train_df=X_train_regular, \n",
    "                                       target=target, \n",
    "                                       train_model_fn= train_model_fn, \n",
    "                                       params_trial_fn = params_trial_fn, \n",
    "                                       kfoldcv= 5),\n",
    "                n_trials=5)\n",
    "\n",
    "best_threshold = study.best_trial.user_attrs['cv_results'].mean(axis = 0)['threshold']\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d33bd0",
   "metadata": {},
   "source": [
    "# Test Set Prediction Using K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234081fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result, avg_probs, models_list = TM.run_cv_evaluation_single_model(X=X_train_regular, \n",
    "                                  y=target, \n",
    "                                  params=best_params, \n",
    "                                  train_model_fn=train_model_fn, \n",
    "                                  kfoldcv=20,\n",
    "                                  test_df=X_test_regular,\n",
    "                                  predict_fn=predict_fn,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00f5f3",
   "metadata": {},
   "source": [
    "# Save Datasets, Settings, Test Predictions to output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769aa446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Directory is at ../Records/xgb_temp\n"
     ]
    }
   ],
   "source": [
    "TM.save_settings(train_df=X_train_regular, \n",
    "              test_df=X_test_regular, \n",
    "              test_id=test_id,\n",
    "              test_pred=avg_probs, \n",
    "              best_params=best_params, \n",
    "              threshold_for_f1=best_threshold, \n",
    "              output_dir=output_dir, \n",
    "              model_name=model_name)\n",
    "print(f'Output Directory is at {output_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
