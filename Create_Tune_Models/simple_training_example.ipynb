{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfe1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yangs\\.conda\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "from scipy.stats import skew, kurtosis\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize']=10,20\n",
    "\n",
    "# Add the grandparent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "from Utils import FE_helper as FE\n",
    "from Utils import training_models as TM\n",
    "from tqdm import tqdm \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669be49",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc8d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the data\n",
    "train_df = pd.read_csv('../Original_Data/train_2025.csv') \n",
    "test_df = pd.read_csv('../Original_Data/test_2025.csv')\n",
    "\n",
    "train_df = FE.add_features(train_df)\n",
    "test_df = FE.add_features(test_df)\n",
    "\n",
    "test_id = test_df['claim_number']\n",
    "train_id = train_df['claim_number']\n",
    "target = train_df['fraud']\n",
    "\n",
    "ignore_var = ['claim_date.is_weekend', 'claim_date.near_holiday', 'fraud']\n",
    "train_df = FE.drop_ignored_columns(train_df, ignore_var)\n",
    "test_df = FE.drop_ignored_columns(test_df, ignore_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c511dc",
   "metadata": {},
   "source": [
    "# Preprocessing Data. Training and Testing Data Needs To Be Fully Numerical Before Proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56718a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_df = train_df\n",
    "updated_test_df = test_df\n",
    "\n",
    "high_dim_cat_cols_to_drop = ['claim_date.day', 'claim_date.dayofweek', 'claim_date.weekofyear', 'claim_date.month']\n",
    "updated_train_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True, errors='ignore')\n",
    "updated_test_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Step 1: Fit on training data\n",
    "onehot, scaler, cat_cols, num_cols = FE.fit_regular_transformer(updated_train_df, '_count')\n",
    "\n",
    "# Step 2: Transform training set itself\n",
    "X_train_regular = FE.transform_regular_set(updated_train_df, onehot, scaler, cat_cols, num_cols)\n",
    "\n",
    "# Step 3: Transform test set (call the same function on test_df)\n",
    "X_test_regular = FE.transform_regular_set(updated_test_df, onehot, scaler, cat_cols, num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c88c6",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a30ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['lgb', 'xgb', 'cat', 'hgb']\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "#################### CHANGE THIS NUMBER TO SWAP MODEL ####################\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "model_name= models_list[0] \n",
    "output_dir = f'../Records/{model_name}_temp'\n",
    "\n",
    "train_model_fn = getattr(TM, f\"train_{model_name}\", None)\n",
    "params_trial_fn= getattr(TM, f\"sample_{model_name}_hyperparams\", None)\n",
    "predict_fn = getattr(TM, f\"predict_{model_name}\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eff47e",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning For the Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa7c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 17:37:53,473] A new study created in memory with name: no-name-799936d2-e73a-49bb-80d2-f2b81d17a83d\n",
      "[I 2025-05-14 17:38:05,663] Trial 0 finished with value: 0.3632242734518843 and parameters: {'num_leaves': 64, 'feature_fraction': 0.4967467731585185, 'bagging_fraction': 0.7955674268308459, 'bagging_freq': 10, 'learning_rate': 0.06852914839727015, 'lambda_l1': 0.01651103615644541, 'lambda_l2': 0.008299320099156564, 'scale_pos_weight': 1.0}. Best is trial 0 with value: 0.3632242734518843.\n",
      "[I 2025-05-14 17:38:19,051] Trial 1 finished with value: 0.3707006593664035 and parameters: {'num_leaves': 51, 'feature_fraction': 0.7134694147637359, 'bagging_fraction': 0.771307475747486, 'bagging_freq': 4, 'learning_rate': 0.09464607199085254, 'lambda_l1': 7.593000993722761, 'lambda_l2': 14.222373065655479, 'scale_pos_weight': 1.0}. Best is trial 1 with value: 0.3707006593664035.\n",
      "[I 2025-05-14 17:38:33,271] Trial 2 finished with value: 0.35075535419723913 and parameters: {'num_leaves': 90, 'feature_fraction': 0.49657231886093395, 'bagging_fraction': 0.5660840918400332, 'bagging_freq': 11, 'learning_rate': 0.09991442054268328, 'lambda_l1': 0.03392921758955719, 'lambda_l2': 0.009740586994407231, 'scale_pos_weight': 1.0}. Best is trial 1 with value: 0.3707006593664035.\n",
      "[I 2025-05-14 17:38:58,830] Trial 3 finished with value: 0.36742184262159855 and parameters: {'num_leaves': 61, 'feature_fraction': 0.5536627773169884, 'bagging_fraction': 0.4585745937387544, 'bagging_freq': 6, 'learning_rate': 0.015339511243220784, 'lambda_l1': 0.16328707913637577, 'lambda_l2': 15.379934266154901, 'scale_pos_weight': 1.0}. Best is trial 1 with value: 0.3707006593664035.\n",
      "[I 2025-05-14 17:39:14,889] Trial 4 finished with value: 0.35642789600221647 and parameters: {'num_leaves': 73, 'feature_fraction': 0.4199920793485238, 'bagging_fraction': 0.6593809363641161, 'bagging_freq': 15, 'learning_rate': 0.057567392503384066, 'lambda_l1': 0.36442834999062296, 'lambda_l2': 0.6278517105810199, 'scale_pos_weight': 1.0}. Best is trial 1 with value: 0.3707006593664035.\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(lambda trial: TM.objective_single_model(trial=trial, \n",
    "                                       full_train_df=X_train_regular, \n",
    "                                       target=target, \n",
    "                                       train_model_fn= train_model_fn, \n",
    "                                       params_trial_fn = params_trial_fn, \n",
    "                                       kfoldcv= 5),\n",
    "                n_trials=5)\n",
    "\n",
    "best_threshold = study.best_trial.user_attrs['cv_results'].mean(axis = 0)['threshold']\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d33bd0",
   "metadata": {},
   "source": [
    "# Test Set Prediction Using K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234081fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result, avg_probs, models_list = TM.run_cv_evaluation_single_model(X=X_train_regular, \n",
    "                                  y=target, \n",
    "                                  params=best_params, \n",
    "                                  train_model_fn=train_model_fn, \n",
    "                                  kfoldcv=20,\n",
    "                                  test_df=X_test_regular,\n",
    "                                  predict_fn=predict_fn,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8283e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_lgb_feature_importance(models, feature_names=None, plot=False, top_n=20):\n",
    "    \"\"\"\n",
    "    Aggregates feature importance from a list of LightGBM models.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of trained lightgbm.Booster objects.\n",
    "        feature_names (list, optional): List of feature names. Required if not stored in model.\n",
    "        plot (bool): Whether to plot the top_n most important features.\n",
    "        top_n (int): Number of top features to display in the plot.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with feature importances (mean and std across models).\n",
    "    \"\"\"\n",
    "    all_importances = []\n",
    "\n",
    "    for model in models:\n",
    "        imp = model.feature_importance(importance_type='gain')\n",
    "        if feature_names is None:\n",
    "            feature_names = model.feature_name()\n",
    "        all_importances.append(pd.Series(imp, index=feature_names))\n",
    "\n",
    "    # Combine into DataFrame\n",
    "    imp_df = pd.concat(all_importances, axis=1)\n",
    "    imp_df.columns = [f'model_{i}' for i in range(len(models))]\n",
    "    imp_df['mean_gain'] = imp_df.mean(axis=1)\n",
    "    imp_df['std_gain'] = imp_df.std(axis=1)\n",
    "    imp_df = imp_df.sort_values('mean_gain', ascending=False).reset_index().rename(columns={'index': 'feature'})\n",
    "\n",
    "    if plot:\n",
    "        top_features = imp_df.head(top_n)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(top_features['feature'][::-1], top_features['mean_gain'][::-1])\n",
    "        plt.xlabel('Mean Gain Importance')\n",
    "        plt.title(f'Top {top_n} Feature Importances (LightGBM)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return imp_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8f542c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = get_lgb_feature_importance(models_list)\n",
    "sub_imp_df = importance_df[['feature', 'mean_gain', 'std_gain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "204b899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_gain</th>\n",
       "      <th>std_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lat</td>\n",
       "      <td>312.399395</td>\n",
       "      <td>169.313432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature   mean_gain    std_gain\n",
       "12     lat  312.399395  169.313432"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_imp_df[sub_imp_df['feature'] == 'lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00f5f3",
   "metadata": {},
   "source": [
    "# Save Datasets, Settings, Test Predictions to output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769aa446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Directory is at ../Records/xgb_temp\n"
     ]
    }
   ],
   "source": [
    "TM.save_settings(train_df=X_train_regular, \n",
    "              test_df=X_test_regular, \n",
    "              test_id=test_id,\n",
    "              test_pred=avg_probs, \n",
    "              best_params=best_params, \n",
    "              threshold_for_f1=best_threshold, \n",
    "              output_dir=output_dir, \n",
    "              model_name=model_name)\n",
    "print(f'Output Directory is at {output_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
