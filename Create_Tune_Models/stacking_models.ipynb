{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfe1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yangs\\.conda\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys\n",
    "import os\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "from scipy.stats import skew, kurtosis\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize']=10,20\n",
    "\n",
    "# Add the grandparent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "from Utils import FE_helper as FE\n",
    "from Utils import training_models as TM\n",
    "from tqdm import tqdm \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669be49",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc8d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the data\n",
    "train_df = pd.read_csv('../Original_Data/train_2025.csv') \n",
    "test_df = pd.read_csv('../Original_Data/test_2025.csv')\n",
    "\n",
    "train_df = FE.add_features(train_df)\n",
    "test_df = FE.add_features(test_df)\n",
    "\n",
    "test_id = test_df['claim_number']\n",
    "train_id = train_df['claim_number']\n",
    "target = train_df['fraud']\n",
    "\n",
    "ignore_var = ['claim_date.is_weekend', 'claim_date.near_holiday', 'fraud']\n",
    "train_df = FE.drop_ignored_columns(train_df, ignore_var)\n",
    "test_df = FE.drop_ignored_columns(test_df, ignore_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c511dc",
   "metadata": {},
   "source": [
    "# Preprocessing Data. Training and Testing Data Needs To Be Fully Numerical Before Proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56718a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_df = train_df\n",
    "updated_test_df = test_df\n",
    "\n",
    "high_dim_cat_cols_to_drop = ['claim_date.day', 'claim_date.dayofweek', 'claim_date.weekofyear', 'claim_date.month']\n",
    "updated_train_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True, errors='ignore')\n",
    "updated_test_df.drop(columns = high_dim_cat_cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Step 1: Fit on training data\n",
    "onehot, scaler, cat_cols, num_cols = FE.fit_regular_transformer(updated_train_df, '_count')\n",
    "\n",
    "# Step 2: Transform training set itself\n",
    "X_train_regular = FE.transform_regular_set(updated_train_df, onehot, scaler, cat_cols, num_cols)\n",
    "\n",
    "# Step 3: Transform test set (call the same function on test_df)\n",
    "X_test_regular = FE.transform_regular_set(updated_test_df, onehot, scaler, cat_cols, num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c88c6",
   "metadata": {},
   "source": [
    "# Importing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72a30ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['lgb', 'xgb', 'cat', 'hgb']\n",
    "output_dir = f\"../Records/{'_'.join(models_list)}_temp\"\n",
    "\n",
    "\n",
    "lgb_params, lgb_threshold = TM.read_settings('../Records/lgb_36096/param_lgb_temp.json')\n",
    "xgb_params, xgb_threshold = TM.read_settings('../Records/xgb_36846/param_xgb_temp.json')\n",
    "cat_params, cat_threshold = TM.read_settings('../Records/cat_37242/param_cat_temp.json')\n",
    "hgb_params, hgb_threshold = TM.read_settings('../Records/hgb_temp/param_hgb_temp.json')\n",
    "\n",
    "param_dict = {\n",
    "    'lgb': {\n",
    "        'params': lgb_params,\n",
    "        'threshold': lgb_threshold\n",
    "    },\n",
    "    'xgb': {\n",
    "        'params': xgb_params,\n",
    "        'threshold': xgb_threshold\n",
    "    },\n",
    "    'cat': {\n",
    "        'params': cat_params,\n",
    "        'threshold': cat_threshold\n",
    "    },\n",
    "    'hgb': {\n",
    "        'params': hgb_params,\n",
    "        'threshold': hgb_threshold\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9db1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stacking_oof_predictions(X, y, params, train_model_fn, kfoldcv=5, drop=[], predict_fn=None, seed=None, verbose = False):\n",
    "    skf = StratifiedKFold(n_splits=kfoldcv, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    oof_thresholds = np.zeros(kfoldcv)\n",
    "    model_list = []\n",
    "    f1_scores = []\n",
    "\n",
    "    i = 1\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx].drop(columns=drop, errors='ignore')\n",
    "        X_val = X.iloc[val_idx].drop(columns=drop, errors='ignore')\n",
    "        y_train = y.iloc[train_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        _, model, stats = train_model_fn(X_train, y_train, X_val, y_val, params)\n",
    "        model_list.append(model)\n",
    "        f1_scores.append(stats['f1'])\n",
    "        oof_thresholds[fold_idx] = stats['threshold']\n",
    "\n",
    "        # Predict on validation fold\n",
    "        probs_val = predict_fn(model, X_val)\n",
    "        oof_preds[val_idx] = probs_val  # assign in correct positions\n",
    "        \n",
    "        if verbose:\n",
    "            pct_progress = (i / kfoldcv)*100\n",
    "            sys.stdout.write(f'\\rCurrently at {pct_progress: .2f}%      ')\n",
    "            sys.stdout.flush()\n",
    "        i += 1\n",
    "\n",
    "    return oof_preds, model_list, f1_scores, oof_thresholds\n",
    "\n",
    "\n",
    "def collect_oof_preds(models_list, param_dict, kfoldcv = 10, seed = None, verbose = False):\n",
    "    \n",
    "    oof_preds_list = []\n",
    "    \n",
    "    for model_name in models_list:\n",
    "        if verbose:\n",
    "            print(f'\\nWorking on Model {model_name}')\n",
    "            \n",
    "        train_model_fn = getattr(TM, f\"train_{model_name}\", None)\n",
    "        predict_fn = getattr(TM, f\"predict_{model_name}\", None)\n",
    "        params = param_dict[model_name]['params']\n",
    "        model_oof_preds , _, _, _ = run_stacking_oof_predictions(X=X_train_regular,\n",
    "                                                                 y=target, \n",
    "                                                                 params=params,\n",
    "                                                                 train_model_fn=train_model_fn, \n",
    "                                                                 kfoldcv=kfoldcv,\n",
    "                                                                 predict_fn=predict_fn,\n",
    "                                                                 seed = seed,\n",
    "                                                                 verbose=verbose)\n",
    "        oof_preds_list.append(model_oof_preds)\n",
    "        \n",
    "    oof_df = pd.DataFrame(oof_preds_list).T\n",
    "    oof_df.columns = models_list\n",
    "    return oof_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f508fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on Model lgb\n",
      "Currently at  100.00%      \n",
      "Working on Model xgb\n",
      "Currently at  100.00%      \n",
      "Working on Model cat\n",
      "Currently at  100.00%      \n",
      "Working on Model hgb\n",
      "Currently at  100.00%      "
     ]
    }
   ],
   "source": [
    "oof_predictions = collect_oof_preds(models_list=models_list, \n",
    "                                    param_dict=param_dict, \n",
    "                                    kfoldcv=10,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1599b5",
   "metadata": {},
   "source": [
    "# Get Base Model Predictions (Probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently working on model lgb\n",
      "Currently working on model xgb\n",
      "Currently working on model cat\n",
      "Currently working on model hgb\n"
     ]
    }
   ],
   "source": [
    "models_list = ['lgb', 'xgb', 'cat', 'hgb']\n",
    "avg_probs_list = []\n",
    "for model_name in models_list:\n",
    "    print(f'Currently working on model {model_name}')\n",
    "    train_model_fn = getattr(TM, f\"train_{model_name}\", None)\n",
    "    params_trial_fn= getattr(TM, f\"sample_{model_name}_hyperparams\", None)\n",
    "    predict_fn = getattr(TM, f\"predict_{model_name}\", None)\n",
    "    \n",
    "    _, avg_probs, _ = TM.run_cv_evaluation_single_model(X=X_train_regular, \n",
    "                                  y=target, \n",
    "                                  params=param_dict[model_name]['params'], \n",
    "                                  train_model_fn=train_model_fn, \n",
    "                                  kfoldcv=20,\n",
    "                                  test_df=X_test_regular,\n",
    "                                  predict_fn=predict_fn,\n",
    "                                  seed=42)\n",
    "    avg_probs_list.append(avg_probs)\n",
    "test_preds = pd.DataFrame(avg_probs_list).T\n",
    "test_preds.columns = models_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b336d8b",
   "metadata": {},
   "source": [
    "# Meta-Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89196c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['lgb', 'xgb', 'cat', 'hgb']\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "#################### CHANGE THIS NUMBER TO SWAP MODEL ####################\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "model_name= models_list[2] \n",
    "\n",
    "train_model_fn = getattr(TM, f\"train_{model_name}\", None)\n",
    "params_trial_fn= getattr(TM, f\"sample_{model_name}_hyperparams\", None)\n",
    "predict_fn = getattr(TM, f\"predict_{model_name}\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eff47e",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning For the Chosen Meta-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa7c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:20:39,148] A new study created in memory with name: no-name-92b31dae-f96a-4be1-a2a6-2370e05c1adf\n",
      "[I 2025-05-11 00:20:46,549] Trial 0 finished with value: 0.3820381833450387 and parameters: {'learning_rate': 0.04253553883355031, 'depth': 8, 'l2_leaf_reg': 0.0013706806267854523, 'colsample_bylevel': 0.7927886563536175}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:20:54,716] Trial 1 finished with value: 0.37946472285366595 and parameters: {'learning_rate': 0.0717159689556057, 'depth': 9, 'l2_leaf_reg': 0.7825246626456087, 'colsample_bylevel': 0.9498430932402357}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:21:01,261] Trial 2 finished with value: 0.37862301102904683 and parameters: {'learning_rate': 0.04581341668439562, 'depth': 6, 'l2_leaf_reg': 0.0026597558800065934, 'colsample_bylevel': 0.9867212953835425}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:21:19,511] Trial 3 finished with value: 0.3764921417887418 and parameters: {'learning_rate': 0.09275515311353279, 'depth': 10, 'l2_leaf_reg': 2.6338946394916447, 'colsample_bylevel': 0.7609814656850221}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:22:34,928] Trial 4 finished with value: 0.38130801473747095 and parameters: {'learning_rate': 0.008594837269323247, 'depth': 10, 'l2_leaf_reg': 0.004028587876965117, 'colsample_bylevel': 0.9249498846301454}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:23:16,316] Trial 5 finished with value: 0.37854314373458336 and parameters: {'learning_rate': 0.019873761896676626, 'depth': 10, 'l2_leaf_reg': 0.46537709705951724, 'colsample_bylevel': 0.5776186673013854}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:23:24,641] Trial 6 finished with value: 0.3777697759014263 and parameters: {'learning_rate': 0.04560601980964716, 'depth': 4, 'l2_leaf_reg': 0.0025179740909866575, 'colsample_bylevel': 0.579601885154357}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:23:49,112] Trial 7 finished with value: 0.38092353935335654 and parameters: {'learning_rate': 0.012764954546230948, 'depth': 3, 'l2_leaf_reg': 0.005283455123375903, 'colsample_bylevel': 0.6451770551645906}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:23:56,342] Trial 8 finished with value: 0.3768372186772372 and parameters: {'learning_rate': 0.06987128851335703, 'depth': 8, 'l2_leaf_reg': 0.006077789928532329, 'colsample_bylevel': 0.5132004909183439}. Best is trial 0 with value: 0.3820381833450387.\n",
      "[I 2025-05-11 00:24:04,298] Trial 9 finished with value: 0.37839492866779295 and parameters: {'learning_rate': 0.07848985537009277, 'depth': 6, 'l2_leaf_reg': 0.6320888936560892, 'colsample_bylevel': 0.5410747034309993}. Best is trial 0 with value: 0.3820381833450387.\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(lambda trial: TM.objective_single_model(trial=trial, \n",
    "                                       full_train_df=oof_predictions, \n",
    "                                       target=target, \n",
    "                                       train_model_fn= train_model_fn, \n",
    "                                       params_trial_fn = params_trial_fn, \n",
    "                                       kfoldcv= 5),\n",
    "                n_trials=10)\n",
    "\n",
    "best_threshold = study.best_trial.user_attrs['cv_results'].mean(axis = 0)['threshold']\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d33bd0",
   "metadata": {},
   "source": [
    "# Test Set Prediction Using K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234081fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result, avg_probs, models_list = TM.run_cv_evaluation_single_model(X=oof_predictions, \n",
    "                                  y=target, \n",
    "                                  params=best_params, \n",
    "                                  train_model_fn=train_model_fn, \n",
    "                                  kfoldcv=20,\n",
    "                                  test_df=test_preds,\n",
    "                                  predict_fn=predict_fn,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00f5f3",
   "metadata": {},
   "source": [
    "# Save Datasets, Settings, Test Predictions to output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "769aa446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Directory is at ../Records/lgb_xgb_cat_hgb_temp\n"
     ]
    }
   ],
   "source": [
    "TM.save_settings(train_df=oof_predictions, \n",
    "              test_df=test_preds, \n",
    "              test_id=test_id,\n",
    "              test_pred=avg_probs, \n",
    "              best_params=best_params, \n",
    "              threshold_for_f1=best_threshold, \n",
    "              output_dir=output_dir, \n",
    "              model_name=model_name)\n",
    "print(f'Output Directory is at {output_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
